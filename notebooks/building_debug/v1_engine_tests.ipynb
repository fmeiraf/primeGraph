{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Test - simple paralle graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History\n",
    "from primeGraph import Graph, START, END\n",
    "from primeGraph.graph.engine import GraphExecutor\n",
    "import time\n",
    "\n",
    "from rich import print as rprint\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "def test_graph(storage=None):\n",
    "    state = StateForTestWithHistory(execution_order=[])\n",
    "    graph = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "    @graph.node()\n",
    "    def task1(state):\n",
    "        time.sleep(1)\n",
    "        print(\"task1\")\n",
    "        return {\"execution_order\": \"task1\"}\n",
    "\n",
    "    @graph.node(interrupt=\"after\")\n",
    "    def task2(state):\n",
    "        time.sleep(2)\n",
    "        print(\"task2\")\n",
    "        return {\"execution_order\": \"task2\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task3(state):\n",
    "        time.sleep(2)\n",
    "        print(\"task3\")\n",
    "        return {\"execution_order\": \"task3\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task4(state):\n",
    "        time.sleep(1)\n",
    "        print(\"task4\")\n",
    "        return {\"execution_order\": \"task4\"}\n",
    "    \n",
    "    @graph.node()\n",
    "    def task5(state):\n",
    "        time.sleep(1)\n",
    "        print(\"task5\")\n",
    "        return {\"execution_order\": \"task5\"}\n",
    "    \n",
    "    @graph.node()\n",
    "    def task6(state):\n",
    "        time.sleep(1)\n",
    "        print(\"task6\")\n",
    "        return {\"execution_order\": \"task6\"}\n",
    "\n",
    "    # Create parallel paths\n",
    "    graph.add_edge(START, \"task1\")\n",
    "    graph.add_edge(\"task1\", \"task2\")\n",
    "    graph.add_edge(\"task1\", \"task3\")\n",
    "    graph.add_edge(\"task2\", \"task4\")\n",
    "    graph.add_edge(\"task3\", \"task5\")\n",
    "    graph.add_edge(\"task4\", \"task6\")\n",
    "    graph.add_edge(\"task5\", \"task6\")\n",
    "    graph.add_edge(\"task6\", END)\n",
    "\n",
    "    graph.compile()\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "graph = test_graph(storage=LocalStorage())\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# In your notebook\n",
    "executor = GraphExecutor(graph)\n",
    "task = asyncio.create_task(executor.execute())  # Start execution\n",
    "\n",
    "# Wait a bit for it to hit the interrupt\n",
    "await asyncio.sleep(5)  \n",
    "\n",
    "# Then call resume to continue\n",
    "# executor.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Add debug logging\n",
    "logging.getLogger('primeGraph.checkpoint.local_storage').setLevel(logging.DEBUG)\n",
    "logging.getLogger('primeGraph.graph.engine').setLevel(logging.DEBUG)\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "task = asyncio.create_task(executor.execute())\n",
    "\n",
    "# Wait a bit and print engine state before checkpoint\n",
    "await asyncio.sleep(4)\n",
    "print(\"\\n=== Engine State BEFORE checkpoint ===\")\n",
    "rprint(executor.get_full_state())\n",
    "\n",
    "# Print checkpoint state right after it's saved\n",
    "await asyncio.sleep(0.1)  # Small delay to ensure checkpoint is saved\n",
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "print(\"\\n=== Checkpoint State ===\")\n",
    "rprint(checkpoint_state.engine_state)\n",
    "\n",
    "# Wait a bit longer for task5 to complete\n",
    "await asyncio.sleep(2)\n",
    "print(\"\\n=== Engine State AFTER task5 completion ===\")\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.checkpoint_storage._storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "last_checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "\n",
    "executor.load_full_state(last_checkpoint_state.engine_state)\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()\n",
    "await executor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.chain_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from primeGraph import Graph, START, END\n",
    "from primeGraph.graph.engine import GraphExecutor\n",
    "import time\n",
    "\n",
    "from rich import print as rprint\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "class RouterState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "def test_graph(storage=None):\n",
    "    state = RouterState(result={}, execution_order=[])\n",
    "    graph = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "    @graph.node()\n",
    "    def process_data(state):\n",
    "        print(\"process_data\")\n",
    "        if True:\n",
    "            return \"route_a\"  # Router node returns next node name\n",
    "        else:\n",
    "            return \"route_b\"\n",
    "\n",
    "    @graph.node()\n",
    "    def route_a(state):\n",
    "        print(\"route_a\")\n",
    "        time.sleep(0.1)\n",
    "        return {\n",
    "            \"result\": {\"path\": \"A\"},\n",
    "            \"execution_order\": \"route_a\",\n",
    "        }\n",
    "\n",
    "    @graph.node()\n",
    "    def route_b(state):\n",
    "        print(\"route_b\")\n",
    "        time.sleep(0.1)\n",
    "        return {\n",
    "            \"result\": {\"path\": \"B\"},\n",
    "            \"execution_order\": \"route_b\",\n",
    "        }\n",
    "\n",
    "    # Add router edge and possible routes\n",
    "    \n",
    "    graph.add_edge(\"route_a\", END)\n",
    "    graph.add_edge(\"route_b\", END)\n",
    "    graph.add_router_edge(START, \"process_data\")\n",
    "\n",
    "    graph.compile()\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "graph = test_graph(storage=LocalStorage())\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Add debug logging\n",
    "logging.getLogger('primeGraph.checkpoint.local_storage').setLevel(logging.DEBUG)\n",
    "logging.getLogger('primeGraph.graph.engine').setLevel(logging.DEBUG)\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "task = asyncio.create_task(executor.execute())\n",
    "\n",
    "# Wait a bit and print engine state before checkpoint\n",
    "await asyncio.sleep(4)\n",
    "print(\"\\n=== Engine State BEFORE checkpoint ===\")\n",
    "rprint(executor.get_full_state())\n",
    "\n",
    "# Print checkpoint state right after it's saved\n",
    "await asyncio.sleep(0.1)  # Small delay to ensure checkpoint is saved\n",
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "print(\"\\n=== Checkpoint State ===\")\n",
    "rprint(checkpoint_state.engine_state)\n",
    "\n",
    "# Wait a bit longer for task5 to complete\n",
    "await asyncio.sleep(2)\n",
    "print(\"\\n=== Engine State AFTER task5 completion ===\")\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.checkpoint_storage._storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "last_checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "\n",
    "executor.load_full_state(last_checkpoint_state.engine_state)\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()\n",
    "await executor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.chain_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "from pydantic import Field, BaseModel\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List, Any\n",
    "from primeGraph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from primeGraph.graph.engine import GraphExecutor\n",
    "from rich import print as rprint\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "sys_prompt_start = \"\"\"\n",
    "You are a helpful assistant that is able to help the user with their goals.\n",
    "\n",
    "You are part of a workflow for the user to plan for something. This is the first step of the workflow.\n",
    "\n",
    "Give the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\n",
    "\n",
    "- They should share their goal in a clear and concise manner\n",
    "- [OPTIONAL] they should share any relevant context or details about the goal\n",
    "- [OPTIONAL] They should express what success looks like for this goal\n",
    "- [OPTIONAL] They should share any constraints or requirements for the goal\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_process_message = \"\"\"\n",
    "\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow in this is the second (and more important) step.\n",
    "\n",
    "Your goal is to analyze the user's message and route them to the next step in the workflow.\n",
    "\n",
    "You will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Analyze current information about the goal and the conversation history\n",
    "- Assess if the information gathered is enough to create a good plan\n",
    "- Route user to the next step in the workflow\n",
    "- Make sure you capture user's intent and route them to the correct step\n",
    "- Make the user experience seemless and seamless\n",
    "\n",
    "==== WORKFLOW STEPS =====\n",
    "\n",
    "Everything evolve around you capacity to create a good plan in the end. \n",
    "Based on the information gathered, evaluate the following:\n",
    "\n",
    "IF information about the goal, details, or anything that can help you create a good plan is needed:\n",
    "- [Follow up questions]\n",
    "    - Ask follow up questions to gather more information about the goal\n",
    "    - Analyze all the information gathered and judge if addional information is needed\n",
    "    - Be clear and concise with the follow up questions\n",
    "\n",
    "IF all the information is gathered and/or the user is ready to move forward, choose between:\n",
    "- [Summarize and ask permission]: \n",
    "    - Help the user visualize the high level plan\n",
    "    - Share your plan into macro steps with a brief summary of what each step entails\n",
    "    - Check if the user would like to proceed with the next step\n",
    "- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\n",
    "\n",
    "Unrelated:\n",
    "- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\n",
    "\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Pay extreme attention to the user's message\n",
    "- Try to understand the user's intent\n",
    "- Always pick only ONE of the options presented to you on WORKFLOW STEPS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_followup = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a follow up step.\n",
    "\n",
    "Your goal is to analyze the user's goal, the information gathered and the conversation history.\n",
    "Based on the information gathered, you should ask follow up questions to gather more information about the goal.\n",
    "\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Analyze current information\n",
    "- Make additional follow up questions ONLY IF NEEDED\n",
    "    - The act of gather more information should be to make sure that the planning process has its goals achieved\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Pay extreme attention to all the curren information gathered\n",
    "- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\n",
    "- Make follow up questions ONLY IF NEEDED\n",
    "    - The act of gather more information should be to make sure that the planning process has its goals achieved\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_summarize = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a summarize step.\n",
    "\n",
    "Your goal is to share with the user a high level overview of the plan you are about to create.\n",
    "Make it short anc concise, but also include all the important details.\n",
    "Make it visually easy to understand and review (on the user's end). \n",
    "Ask if the user would like to proceed with the next step.\n",
    "\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Summarize the plan in a way that is easy to understand and review\n",
    "- Make it visually easy to understand and review (on the user's end)\n",
    "- Ask if the user would like to proceed with the next step\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Make sure you include all the important details\n",
    "- Make sure you have a decent break down of the plan\n",
    "- Make it visually easy to understand and review (on the user's end)\n",
    "- Ask if the user would like to proceed with the next step\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_finalize = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a finalize step.\n",
    "\n",
    "Your goal is to say goodbye to the user and thank them for using your service.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class PlannerState(GraphState):\n",
    "    conversation: History[Dict[str, str]] = Field(default_factory=list)\n",
    "    model_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]] = Field(default=None)\n",
    "    is_summarize: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_finalize: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_outside_of_the_workflow: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    plan_goal: LastValue[str] = Field(default=\"\")\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_steps: LastValue[List[str]] = Field(default_factory=list)\n",
    "    plan_details: History[str] = Field(default_factory=list)\n",
    "    current_information_assessment: LastValue[str] = Field(default=\"\")\n",
    "    follow_up_questions: LastValue[List[str]] = Field(default_factory=list)\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_steps: LastValue[List[str]] = Field(default_factory=list)\n",
    "\n",
    "def planner_graph(graph_state: PlannerState, checkpoint_storage: Union[PostgreSQLStorage, None]) -> Graph:\n",
    "    plan_graph = Graph(state=graph_state, verbose=True, checkpoint_storage=checkpoint_storage)\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def start_conversation(state: PlannerState) -> dict[str, Any]:\n",
    "        class StartConversationResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=StartConversationResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_start},\n",
    "            ],\n",
    "        )\n",
    "        return {\"conversation\": {\"role\": \"assistant\", \"content\": completion.response}}\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def process_user_message(state: PlannerState) -> dict[str, Any]:\n",
    "        class ProcessMessageResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional relevant details of the plan\")\n",
    "            is_followup: bool # = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_summarize: bool # = Field(description=\"If there are not follow up questions on your end.\")\n",
    "            is_finalize: bool # = Field(\n",
    "            #     description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            # )\n",
    "            is_outside_of_the_workflow: bool # = Field(\n",
    "            #     description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            # )\n",
    "\n",
    "        # add user message to the conversation\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=ProcessMessageResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_process_message},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"plan_goal\": completion.plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": None,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_summarize\": completion.is_summarize,\n",
    "            \"is_finalize\": completion.is_finalize,\n",
    "            \"is_outside_of_the_workflow\": completion.is_outside_of_the_workflow,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def response_router(state: PlannerState) -> str:\n",
    "        if state.is_finalize:\n",
    "            return \"finalize_plan\"\n",
    "        elif state.is_summarize:\n",
    "            return \"summarize_plan\"\n",
    "        elif state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        else:\n",
    "            return \"process_user_message\"\n",
    "                \n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def make_followup_questions(state: PlannerState):\n",
    "        class FollowupResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional you got from your interactions with the user\")\n",
    "            current_information_assessment: str = Field(description=\"A brief assessment of the current information gathered\")\n",
    "            follow_up_questions: List[str] = Field(description=\"The follow up questions that you think are needed to gather more information about the goal\")\n",
    "            response: str = Field(description=\"Your response with the follow up questions\")\n",
    "\n",
    "    \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FollowupResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_followup},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"current_information_assessment\": completion.current_information_assessment,\n",
    "            \"follow_up_questions\": completion.follow_up_questions,\n",
    "        }\n",
    "  \n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def summarize_plan(state: PlannerState):\n",
    "        class SummarizeResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            plan_summary: str = Field(description=\"A summary of the plan\")\n",
    "            plan_steps: List[str] = Field(description=\"A list of the steps that are part of the plan\")\n",
    "\n",
    "            \n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=SummarizeResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_summarize},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"plan_summary\": completion.plan_summary,\n",
    "            \"plan_steps\": completion.plan_steps,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    def finalize_plan(state: PlannerState):\n",
    "        class FinalizeResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FinalizeResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_finalize},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "        }\n",
    "\n",
    "\n",
    "    plan_graph.add_edge(START, \"start_conversation\")\n",
    "    plan_graph.add_edge(\"start_conversation\", \"process_user_message\")\n",
    "    plan_graph.add_router_edge(\"process_user_message\", \"response_router\")\n",
    "\n",
    "    plan_graph.add_edge(\"summarize_plan\", \"process_user_message\")\n",
    "    plan_graph.add_edge(\"make_followup_questions\", \"process_user_message\")\n",
    "    plan_graph.add_edge(\"finalize_plan\", END)\n",
    "    \n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Patching `client.chat.completions.create` with mode=<Mode.TOOLS: 'tool_call'>\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"568pt\" height=\"489pt\"\n",
       " viewBox=\"21.60 21.60 546.83 467.31\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(25.6 463.31)\">\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"278.93\" cy=\"-419.58\" rx=\"49\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-415.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__start__</text>\n",
       "</g>\n",
       "<!-- start_conversation -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>start_conversation</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M199.12,-335.94C199.12,-335.94 358.73,-335.94 358.73,-335.94 364.73,-335.94 370.73,-341.94 370.73,-347.94 370.73,-347.94 370.73,-359.94 370.73,-359.94 370.73,-365.94 364.73,-371.94 358.73,-371.94 358.73,-371.94 199.12,-371.94 199.12,-371.94 193.12,-371.94 187.12,-365.94 187.12,-359.94 187.12,-359.94 187.12,-347.94 187.12,-347.94 187.12,-341.94 193.12,-335.94 199.12,-335.94\"/>\n",
       "<text text-anchor=\"start\" x=\"201.53\" y=\"-350.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">start_conversation</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"296.18,-335.94 296.18,-371.94\"/>\n",
       "<text text-anchor=\"start\" x=\"310.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"316.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"319.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;start_conversation -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;start_conversation</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-400.94C278.93,-400.94 278.93,-383.91 278.93,-383.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-383.91 278.93,-373.91 275.43,-383.91 282.43,-383.91\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"278.93\" cy=\"-18.14\" rx=\"46.35\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-14.26\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__end__</text>\n",
       "</g>\n",
       "<!-- process_user_message -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>process_user_message</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M333.08,-306.44C333.08,-306.44 224.78,-306.44 224.78,-306.44 218.78,-306.44 212.78,-300.44 212.78,-294.44 212.78,-294.44 212.78,-282.44 212.78,-282.44 212.78,-276.44 218.78,-270.44 224.78,-270.44 224.78,-270.44 333.08,-270.44 333.08,-270.44 339.08,-270.44 345.08,-276.44 345.08,-282.44 345.08,-282.44 345.08,-294.44 345.08,-294.44 345.08,-300.44 339.08,-306.44 333.08,-306.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-284.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">process_user_message</text>\n",
       "</g>\n",
       "<!-- start_conversation&#45;&gt;process_user_message -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>start_conversation&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-335.69C278.93,-335.69 278.93,-318.1 278.93,-318.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-318.1 278.93,-308.1 275.43,-318.1 282.43,-318.1\"/>\n",
       "</g>\n",
       "<!-- response_router -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>response_router</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M270.44,-232.96C270.44,-232.96 232.33,-194.84 232.33,-194.84 228.08,-190.6 228.08,-182.11 232.33,-177.87 232.33,-177.87 270.44,-139.76 270.44,-139.76 274.68,-135.52 283.17,-135.52 287.41,-139.76 287.41,-139.76 325.52,-177.87 325.52,-177.87 329.77,-182.11 329.77,-190.6 325.52,-194.84 325.52,-194.84 287.41,-232.96 287.41,-232.96 283.17,-237.2 274.68,-237.2 270.44,-232.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-188.11\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">response</text>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-176.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">router</text>\n",
       "</g>\n",
       "<!-- process_user_message&#45;&gt;response_router -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>process_user_message&#45;&gt;response_router</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.29,-270.19C297.29,-270.19 297.29,-234.99 297.29,-234.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.79,-234.99 297.29,-224.99 293.79,-234.99 300.79,-234.99\"/>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;process_user_message -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M260.56,-223.5C260.56,-223.5 260.56,-258.56 260.56,-258.56\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"257.06,-258.56 260.56,-268.56 264.06,-258.56 257.06,-258.56\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>make_followup_questions</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M12,-65.77C12,-65.77 203.85,-65.77 203.85,-65.77 209.85,-65.77 215.85,-71.77 215.85,-77.77 215.85,-77.77 215.85,-89.77 215.85,-89.77 215.85,-95.77 209.85,-101.77 203.85,-101.77 203.85,-101.77 12,-101.77 12,-101.77 6,-101.77 0,-95.77 0,-89.77 0,-89.77 0,-77.77 0,-77.77 0,-71.77 6,-65.77 12,-65.77\"/>\n",
       "<text text-anchor=\"start\" x=\"14.4\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">make_followup_questions</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"141.3,-65.77 141.3,-101.77\"/>\n",
       "<text text-anchor=\"start\" x=\"155.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"161.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"164.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M228.21,-181.45C228.21,-161.81 228.21,-90 228.21,-90 228.21,-90 227.01,-90 227.01,-90\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"227.75,-86.5 217.75,-90 227.75,-93.5 227.75,-86.5\"/>\n",
       "</g>\n",
       "<!-- summarize_plan -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>summarize_plan</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M354.62,-65.77C354.62,-65.77 505.23,-65.77 505.23,-65.77 511.23,-65.77 517.23,-71.77 517.23,-77.77 517.23,-77.77 517.23,-89.77 517.23,-89.77 517.23,-95.77 511.23,-101.77 505.23,-101.77 505.23,-101.77 354.62,-101.77 354.62,-101.77 348.62,-101.77 342.62,-95.77 342.62,-89.77 342.62,-89.77 342.62,-77.77 342.62,-77.77 342.62,-71.77 348.62,-65.77 354.62,-65.77\"/>\n",
       "<text text-anchor=\"start\" x=\"357.03\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">summarize_plan</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"442.68,-65.77 442.68,-101.77\"/>\n",
       "<text text-anchor=\"start\" x=\"457.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"463.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"466.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;summarize_plan -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;summarize_plan</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M329.64,-181.42C329.64,-160.22 329.64,-78 329.64,-78 329.64,-78 330.91,-78 330.91,-78\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"330.83,-81.5 340.83,-78 330.83,-74.5 330.83,-81.5\"/>\n",
       "</g>\n",
       "<!-- finalize_plan -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>finalize_plan</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M308.32,-101.77C308.32,-101.77 249.53,-101.77 249.53,-101.77 243.53,-101.77 237.53,-95.77 237.53,-89.77 237.53,-89.77 237.53,-77.77 237.53,-77.77 237.53,-71.77 243.53,-65.77 249.53,-65.77 249.53,-65.77 308.32,-65.77 308.32,-65.77 314.32,-65.77 320.32,-71.77 320.32,-77.77 320.32,-77.77 320.32,-89.77 320.32,-89.77 320.32,-95.77 314.32,-101.77 308.32,-101.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">finalize_plan</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;finalize_plan -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;finalize_plan</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M278.93,-130.86C278.93,-130.86 278.93,-113.63 278.93,-113.63\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"282.43,-113.63 278.93,-103.63 275.43,-113.63 282.43,-113.63\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions&#45;&gt;process_user_message -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>make_followup_questions&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.12,-78C218.51,-78 219.85,-78 219.85,-78 219.85,-78 219.85,-258.62 219.85,-258.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.35,-258.62 219.85,-268.62 223.35,-258.62 216.35,-258.62\"/>\n",
       "</g>\n",
       "<!-- summarize_plan&#45;&gt;process_user_message -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>summarize_plan&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M342.25,-90C339.75,-90 338.32,-90 338.32,-90 338.32,-90 338.32,-258.61 338.32,-258.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.82,-258.61 338.32,-268.61 341.82,-258.61 334.82,-258.61\"/>\n",
       "</g>\n",
       "<!-- finalize_plan&#45;&gt;__end__ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>finalize_plan&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-65.49C278.93,-65.49 278.93,-47.84 278.93,-47.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-47.84 278.93,-37.84 275.43,-47.84 282.43,-47.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x11b093990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "graph = planner_graph(checkpoint_storage=LocalStorage(), graph_state=PlannerState())\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node '__start__' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'start_conversation' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.start_conversation.<locals>.StartConversationResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b3337d0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11b071010> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b0ff1d0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 07 Feb 2025 04:10:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1479'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999835'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_1768c0c9d5721867c023a2a02f263c91'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Xb71FXX.eC9sW5a8KdL3idMj_7CxlJ8Wzue4WnZP_oY-1738901417-1.0.1.1-G5LLogjy1AJBHGNRP57K.CDpohMt5OsHSeahMoCrB3Bq5.8vS1gVRkwQwQqZJX1HpmEkKQvZDLG7yuWCn1hwHA; path=/; expires=Fri, 07-Feb-25 04:40:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7Hkzt9B_6FytB03XgARTdkYH2ZhaCsDFKnQBzRu_Z9I-1738901417133-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90e087769f29421a-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Fri, 07 Feb 2025 04:10:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'lfm-l6lfkw'), ('openai-processing-ms', '1479'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999835'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_1768c0c9d5721867c023a2a02f263c91'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Xb71FXX.eC9sW5a8KdL3idMj_7CxlJ8Wzue4WnZP_oY-1738901417-1.0.1.1-G5LLogjy1AJBHGNRP57K.CDpohMt5OsHSeahMoCrB3Bq5.8vS1gVRkwQwQqZJX1HpmEkKQvZDLG7yuWCn1hwHA; path=/; expires=Fri, 07-Feb-25 04:40:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7Hkzt9B_6FytB03XgARTdkYH2ZhaCsDFKnQBzRu_Z9I-1738901417133-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90e087769f29421a-YYC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_1768c0c9d5721867c023a2a02f263c91\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-Ay9yxpyFQ0EEQO4oBlU2AGn00wKKF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L8TVanxlXyxsU9hgcizyu6ud', function=Function(arguments='{\"response\":\"Welcome! I\\'m here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let\\'s get started!\"}', name='StartConversationResponse'), type='function')]))], created=1738901415, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_50cad350e4', usage=CompletionUsage(completion_tokens=55, prompt_tokens=200, total_tokens=255, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.local_storage:Checkpoint 'checkpoint_be88f7b1-b129-4fe7-bb4d-b29bf9988885' saved in memory.\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: start_conversation\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'start_conversation'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manner. Feel free to include any relevant details, what success looks like for you, and any constraints or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements you have in mind. Let's get started!\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise \u001b[0m\n",
       "\u001b[32mmanner. Feel free to include any relevant details, what success looks like for you, and any constraints or \u001b[0m\n",
       "\u001b[32mrequirements you have in mind. Let's get started!\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executor = GraphExecutor(graph)\n",
    "\n",
    "await executor.execute()\n",
    "rprint(graph.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.engine:Resuming execution...\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'process_user_message' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.process_user_message.<locals>.ProcessMessageResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 07 Feb 2025 04:10:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1924'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999368'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'18ms'), (b'x-request-id', b'req_bd00cdd7eebb0d5cdfc2f7a332f7e211'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90e0879ecd08421a-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 07 Feb 2025 04:10:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '1924', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999368', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '18ms', 'x-request-id': 'req_bd00cdd7eebb0d5cdfc2f7a332f7e211', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90e0879ecd08421a-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_bd00cdd7eebb0d5cdfc2f7a332f7e211\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-Ay9z6iQ7L2rNg6H50kWgKbEdOv8rZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HD3zZmhCWa3gzMuaU1B6KzgA', function=Function(arguments='{\"plan_goal\":\"\",\"plan_details\":[],\"is_followup\":true,\"is_summarize\":false,\"is_finalize\":false,\"is_outside_of_the_workflow\":false}', name='ProcessMessageResponse'), type='function')]))], created=1738901424, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=37, prompt_tokens=669, total_tokens=706, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.local_storage:Checkpoint 'checkpoint_5c985cb1-fd9d-4cbb-a89e-ffdd1b9ce6fc' saved in memory.\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: process_user_message\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'response_router' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Router node 'response_router' routing to node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'response_router' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'process_user_message' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'make_followup_questions' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.make_followup_questions.<locals>.FollowupResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 07 Feb 2025 04:10:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'5589'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999647'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_018c034d61bedf70331a75aace947389'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90e087b718f3421a-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 07 Feb 2025 04:10:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '5589', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999647', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_018c034d61bedf70331a75aace947389', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90e087b718f3421a-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_018c034d61bedf70331a75aace947389\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-Ay9z760k3JKGPgAPaymZbm9cJEHQp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3wBBv6iHaegQanQg5FVXtbur', function=Function(arguments='{\"plan_goal\":\"Goal not provided yet.\",\"plan_details\":[],\"current_information_assessment\":\"The user has not provided any information about their goal or the context in which they are seeking assistance. Current information is completely lacking, making it impossible to proceed with any planning steps.\",\"follow_up_questions\":[\"What is the goal you are trying to achieve?\"],\"response\":\"I noticed that you haven\\'t shared the goal you\\'re working towards. Could you please provide more details about what you\\'re aiming to achieve? This will help me assist you better.\"}', name='FollowupResponse'), type='function')]))], created=1738901425, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=106, prompt_tokens=449, total_tokens=555, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.local_storage:Checkpoint 'checkpoint_39daa2ed-51d6-4ec7-bec2-5ee9d0f1936b' saved in memory.\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'make_followup_questions'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manner. Feel free to include any relevant details, what success looks like for you, and any constraints or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements you have in mind. Let's get started!\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I noticed that you haven't shared the goal you're working towards. Could you please provide</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">more details about what you're aiming to achieve? This will help me assist you better.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"I noticed that you haven't shared the goal you're working towards. Could you please provide more</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details about what you're aiming to achieve? This will help me assist you better.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user has not provided any information about their goal or the context in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which they are seeking assistance. Current information is completely lacking, making it impossible to proceed with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">any planning steps.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'What is the goal you are trying to achieve?'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise \u001b[0m\n",
       "\u001b[32mmanner. Feel free to include any relevant details, what success looks like for you, and any constraints or \u001b[0m\n",
       "\u001b[32mrequirements you have in mind. Let's get started!\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"I noticed that you haven't shared the goal you're working towards. Could you please provide\u001b[0m\n",
       "\u001b[32mmore details about what you're aiming to achieve? This will help me assist you better.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m\"I\u001b[0m\u001b[32m noticed that you haven't shared the goal you're working towards. Could you please provide more\u001b[0m\n",
       "\u001b[32mdetails about what you're aiming to achieve? This will help me assist you better.\"\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m'The user has not provided any information about their goal or the context in \u001b[0m\n",
       "\u001b[32mwhich they are seeking assistance. Current information is completely lacking, making it impossible to proceed with \u001b[0m\n",
       "\u001b[32many planning steps.'\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'What is the goal you are trying to achieve?'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await executor.resume()\n",
    "rprint(graph.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.engine:Resuming execution...\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'process_user_message' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}] model_message=\"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\" user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='The user has not provided any information about their goal or the context in which they are seeking assistance. Current information is completely lacking, making it impossible to proceed with any planning steps.' follow_up_questions=['What is the goal you are trying to achieve?']\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.process_user_message.<locals>.ProcessMessageResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b3a49d0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x11b071010> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11b3a7690>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 07 Feb 2025 04:10:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'906'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999321'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'20ms'), (b'x-request-id', b'req_c3a04bc15f86345061f9b58e3f4e2c64'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90e088261ca001d2-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 07 Feb 2025 04:10:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '906', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999321', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '20ms', 'x-request-id': 'req_c3a04bc15f86345061f9b58e3f4e2c64', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90e088261ca001d2-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_c3a04bc15f86345061f9b58e3f4e2c64\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-Ay9zPLycD2jRoaukDAVP2Yk31UzpB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_mZftiwzi4KkO7lwzslIdcQMg', function=Function(arguments='{\"plan_goal\":\"\",\"plan_details\":[],\"is_followup\":true,\"is_summarize\":false,\"is_finalize\":false,\"is_outside_of_the_workflow\":false}', name='ProcessMessageResponse'), type='function')]))], created=1738901443, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=37, prompt_tokens=706, total_tokens=743, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.local_storage:Checkpoint 'checkpoint_0c9b28be-a50c-4aea-b0b2-bd930bf3e730' saved in memory.\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: process_user_message\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'response_router' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='The user has not provided any information about their goal or the context in which they are seeking assistance. Current information is completely lacking, making it impossible to proceed with any planning steps.' follow_up_questions=['What is the goal you are trying to achieve?']\n",
      "DEBUG:primeGraph.graph.engine:Router node 'response_router' routing to node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'response_router' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'process_user_message' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'make_followup_questions' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'make_followup_questions' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='The user has not provided any information about their goal or the context in which they are seeking assistance. Current information is completely lacking, making it impossible to proceed with any planning steps.' follow_up_questions=['What is the goal you are trying to achieve?']\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.make_followup_questions.<locals>.FollowupResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal. Please share it in a clear and concise manner. Feel free to include any relevant details, what success looks like for you, and any constraints or requirements you have in mind. Let's get started!\"}, {'role': 'assistant', 'content': \"I noticed that you haven't shared the goal you're working towards. Could you please provide more details about what you're aiming to achieve? This will help me assist you better.\"}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 07 Feb 2025 04:10:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'6023'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999602'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_fd80c0b2f0377a2c6d42887d885d1c96'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90e0882cfb9501d2-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 07 Feb 2025 04:10:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '6023', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999602', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_fd80c0b2f0377a2c6d42887d885d1c96', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90e0882cfb9501d2-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_fd80c0b2f0377a2c6d42887d885d1c96\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-Ay9zQYRjfGVi1ImPD592239k4tC5B', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OMUdJQTHEJXE7U6OeOmhWdY7', function=Function(arguments='{\"plan_goal\":\"\",\"plan_details\":[],\"current_information_assessment\":\"No information has been provided by the user about the goal or any relevant details.\",\"follow_up_questions\":[\"What is the goal you are trying to achieve?\",\"Are there any specific constraints or requirements for this goal?\",\"What does success look like for you in achieving this goal?\"],\"response\":\"It seems like we haven\\'t started on your goal yet. Could you please share what you\\'re aiming to achieve? Additionally, if there are any specific requirements or what success looks like for you, that would be helpful as well.\"}', name='FollowupResponse'), type='function')]))], created=1738901444, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=117, prompt_tokens=486, total_tokens=603, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.local_storage:Checkpoint 'checkpoint_8410ccf8-3dfc-447f-82a6-2b28864fc86c' saved in memory.\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'make_followup_questions'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manner. Feel free to include any relevant details, what success looks like for you, and any constraints or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements you have in mind. Let's get started!\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I noticed that you haven't shared the goal you're working towards. Could you please provide</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">more details about what you're aiming to achieve? This will help me assist you better.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"It seems like we haven't started on your goal yet. Could you please share what you're </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aiming to achieve? Additionally, if there are any specific requirements or what success looks like for you, that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">would be helpful as well.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"It seems like we haven't started on your goal yet. Could you please share what you're aiming to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">achieve? Additionally, if there are any specific requirements or what success looks like for you, that would be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helpful as well.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'No information has been provided by the user about the goal or any relevant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What is the goal you are trying to achieve?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Are there any specific constraints or requirements for this goal?'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'What does success look like for you in achieving this goal?'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal. Please share it in a clear and concise \u001b[0m\n",
       "\u001b[32mmanner. Feel free to include any relevant details, what success looks like for you, and any constraints or \u001b[0m\n",
       "\u001b[32mrequirements you have in mind. Let's get started!\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"I noticed that you haven't shared the goal you're working towards. Could you please provide\u001b[0m\n",
       "\u001b[32mmore details about what you're aiming to achieve? This will help me assist you better.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"It seems like we haven't started on your goal yet. Could you please share what you're \u001b[0m\n",
       "\u001b[32maiming to achieve? Additionally, if there are any specific requirements or what success looks like for you, that \u001b[0m\n",
       "\u001b[32mwould be helpful as well.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m\"It\u001b[0m\u001b[32m seems like we haven't started on your goal yet. Could you please share what you're aiming to \u001b[0m\n",
       "\u001b[32machieve? Additionally, if there are any specific requirements or what success looks like for you, that would be \u001b[0m\n",
       "\u001b[32mhelpful as well.\"\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m'No information has been provided by the user about the goal or any relevant \u001b[0m\n",
       "\u001b[32mdetails.'\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'What is the goal you are trying to achieve?'\u001b[0m,\n",
       "        \u001b[32m'Are there any specific constraints or requirements for this goal?'\u001b[0m,\n",
       "        \u001b[32m'What does success look like for you in achieving this goal?'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await executor.resume()\n",
    "rprint(graph.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Add debug logging\n",
    "logging.getLogger('primeGraph.checkpoint.local_storage').setLevel(logging.DEBUG)\n",
    "logging.getLogger('primeGraph.graph.engine').setLevel(logging.DEBUG)\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "task = asyncio.create_task(executor.execute())\n",
    "\n",
    "# Wait a bit and print engine state before checkpoint\n",
    "await asyncio.sleep(4)\n",
    "print(\"\\n=== Engine State BEFORE checkpoint ===\")\n",
    "rprint(executor.get_full_state())\n",
    "\n",
    "# Print checkpoint state right after it's saved\n",
    "await asyncio.sleep(0.1)  # Small delay to ensure checkpoint is saved\n",
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "print(\"\\n=== Checkpoint State ===\")\n",
    "rprint(checkpoint_state.engine_state)\n",
    "\n",
    "# Wait a bit longer for task5 to complete\n",
    "await asyncio.sleep(2)\n",
    "print(\"\\n=== Engine State AFTER task5 completion ===\")\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.checkpoint_storage._storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = list(graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]].keys())[-1]\n",
    "last_checkpoint_state = graph.checkpoint_storage._storage[list(graph.checkpoint_storage._storage.keys())[0]][last_checkpoint]\n",
    "\n",
    "executor = GraphExecutor(graph)\n",
    "\n",
    "executor.load_full_state(last_checkpoint_state.engine_state)\n",
    "rprint(executor.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor.resume()\n",
    "await executor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.chain_status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
