{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.constants import START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution plan conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    print(\"g \\n\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"b\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"c\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"e\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    time.sleep(1)\n",
    "    print(\"g\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"c\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"e\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "# Create a test graph with a mix of parallel and sequential paths\n",
    "test_graph = Graph()\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def start_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting workflow \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_1():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 1 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 1 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_2():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 2 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 2 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def final_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Running final task \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# Create a workflow with parallel execution\n",
    "test_graph.add_edge(START, \"start_task\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_1\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_2\")\n",
    "test_graph.add_edge(\"parallel_task_1\", \"final_task\")\n",
    "test_graph.add_edge(\"parallel_task_2\", \"final_task\")\n",
    "test_graph.add_edge(\"final_task\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "print(\"\\nExecution Plan:\")\n",
    "rprint(test_graph.execution_plan)\n",
    "print(\"\\nStarting execution:\")\n",
    "start_time = time.time()\n",
    "test_graph.execute()\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node()\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(f\"Counter: {test_graph.state.counter}\")  # Should be 8 (5 + 3)\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should contain both metric updates\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from typing import Dict\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.constants import START, END\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@test_graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_status(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "# Create the workflow with parallel execution\n",
    "test_graph.add_edge(START, \"increment_counter\")\n",
    "test_graph.add_edge(START, \"decrement_counter\")\n",
    "test_graph.add_edge(START, \"update_status\")\n",
    "test_graph.add_edge(\"increment_counter\", END)\n",
    "test_graph.add_edge(\"decrement_counter\", END)\n",
    "test_graph.add_edge(\"update_status\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(\n",
    "    f\"Counter: {test_graph.state.counter}\"\n",
    ")  # Should reflect the net effect of increments and decrements\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should be empty as no metrics are updated\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"in_progress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(\"process_data\", \"validate\")\n",
    "graph.add_edge(\"validate\", \"escape\")\n",
    "graph.add_edge(\"escape\", \"prep\")\n",
    "graph.add_edge(\"validate\", \"aa\")\n",
    "graph.add_edge(\"aa\", \"bb\")\n",
    "graph.add_edge(\"bb\", \"prep\")\n",
    "graph.add_edge(\"prep\", END)\n",
    "\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import Incremental, LastValue, History\n",
    "from typing import Dict\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "\n",
    "\n",
    "graph.start(timeout=10)\n",
    "\n",
    "rprint(graph.state)\n",
    "\n",
    "# Assert final state\n",
    "assert (\n",
    "    graph.state.counter == 1\n",
    "), \"Counter should reflect net effect of increments and decrements\"\n",
    "assert graph.state.status == \"complete\", \"Status should be 'complete'\"\n",
    "assert len(graph.state.metrics) == 3, \"Metrics should contain three updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import Incremental, LastValue, History\n",
    "from typing import Dict\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={\"xablau\": 2.0})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"counter\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"metrics\"].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(simple_graph._convert_execution_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_execution_plan(plan, metadata):\n",
    "    def slice_list(lst, meta):\n",
    "        result = []\n",
    "        for item in lst:\n",
    "            if isinstance(item, list):\n",
    "                # Recursively slice nested lists\n",
    "                sliced_item = slice_list(item, meta)\n",
    "                if sliced_item:\n",
    "                    result.append(sliced_item)\n",
    "            else:\n",
    "                # Check metadata for slicing\n",
    "                if meta.get(item) == \"before\":\n",
    "                    break\n",
    "                result.append(item)\n",
    "                if meta.get(item) == \"after\":\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    return slice_list(plan, metadata)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "execution_plan = [\n",
    "    \"process_data\",\n",
    "    \"validate\",\n",
    "    [[\"escape\", [\"dd\", \"cc\"], \"hh\"], [\"aa\", \"bb\"]],\n",
    "    \"prep\",\n",
    "]\n",
    "metadata = {\n",
    "    # 'process_data': 'after',\n",
    "    # 'validate': 'before',\n",
    "    # 'escape': 'after',\n",
    "    \"dd\": \"before\",\n",
    "    # 'cc': 'after',\n",
    "    # 'hh': 'before',\n",
    "    # 'aa': 'after',\n",
    "    # 'bb': 'before',\n",
    "    # 'prep': 'after'\n",
    "}\n",
    "\n",
    "sliced_plan = slice_execution_plan(execution_plan, metadata)\n",
    "print(sliced_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_plan[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem here is that in the case of update_status_to_complete,\n",
    "# it's not checking if the next node is a convergence point\n",
    "\n",
    "# it needs to have a function that will check if the next node\n",
    "# connector. find_convergence_point is not doing enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing interruption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from typing import Dict\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = escape\n",
    "\n",
    "x.__metadata__[\"interrupt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    time.sleep(0.5)\n",
    "    print(\"escape\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    time.sleep(1.5)\n",
    "    print(\"process_data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    time.sleep(0.5)\n",
    "    print(\"validate\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    time.sleep(1.5)\n",
    "    print(\"aa\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    time.sleep(0.5)\n",
    "    print(\"bb\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    time.sleep(1.5)\n",
    "    print(\"dd\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    time.sleep(1.5)\n",
    "    print(\"cc\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    time.sleep(0.5)\n",
    "    print(\"hh\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    time.sleep(0.5)\n",
    "    print(\"prep\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "simple_graph._convert_execution_plan()\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.graph.executable import ExecutableNode\n",
    "from typing import Union, List, Tuple\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "def add_item_to_obj_store(obj_store: Union[List, Tuple], item):\n",
    "    if isinstance(obj_store, list):\n",
    "        obj_store.append(item)\n",
    "        return obj_store  # Return the modified list\n",
    "    elif isinstance(obj_store, tuple):\n",
    "        return obj_store + (item,)  # Already returns the new tuple\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object store type: {type(obj_store)}\")\n",
    "\n",
    "\n",
    "def extract_tasks_from_node(node, tasks=[]):\n",
    "    \"\"\"\n",
    "    Extracts tasks from a node, including nested nodes\n",
    "    returns lists for sequential execution and tuples for parallel execution\n",
    "    \"\"\"\n",
    "    tasks = [] if node.execution_type == \"sequential\" else tuple()\n",
    "    for task in node.task_list:\n",
    "        if isinstance(task, ExecutableNode):\n",
    "            if task.execution_type == \"sequential\":\n",
    "                tasks = add_item_to_obj_store(tasks, extract_tasks_from_node(task, []))\n",
    "            else:\n",
    "                tasks = add_item_to_obj_store(\n",
    "                    tasks, extract_tasks_from_node(task, tuple())\n",
    "                )\n",
    "        else:\n",
    "            tasks = add_item_to_obj_store(tasks, task)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "rprint(extract_tasks_from_node(simple_graph.execution_plan[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import Incremental, LastValue, History\n",
    "from typing import Dict\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=0, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"increment_counter\")\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"decrement_counter\")\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_in_progress\")\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_complete\")\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"finalize_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "graph._convert_execution_plan()\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import History\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def task2(state):\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task3(state):\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[edge.id for edge in graph.edges if edge.end_node == \"__start__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Async Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 (testing non-async using execute_async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from typing import Dict\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics=[], current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "def step_1():\n",
    "    time.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_A():\n",
    "    time.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_B():\n",
    "    time.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_2():\n",
    "    time.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "async def step_1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_A():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_B():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_2():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import History\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task1(state):\n",
    "    print(\"task1\")\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task2(state):\n",
    "    print(\"task2\")\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "async def task3(state):\n",
    "    print(\"task3\")\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task4(state):\n",
    "    print(\"task4\")\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "# Create parallel paths\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task1\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()\n",
    "\n",
    "# First execution should execute task1 and task3, but pause before task2\n",
    "# await graph.start_async()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.models.state import GraphState\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "StateForTestWithHistory(execution_order=[\"a\", 2], counter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "ComplexTestState(counter=0, status=\"\", metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "class SimpleGraphState(GraphState):\n",
    "    messages: History[str]\n",
    "\n",
    "\n",
    "# Create state instance\n",
    "state = SimpleGraphState(messages=[])\n",
    "\n",
    "# Update graph with state\n",
    "storage = LocalStorage()\n",
    "graph1 = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_hello(state: GraphState):\n",
    "    return {\"messages\": \"Hello\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_world(state: GraphState):\n",
    "    return {\"messages\": \"World\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_exclamation(state: GraphState):\n",
    "    return {\"messages\": \"!\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "graph1.add_edge(START, \"add_hello\")\n",
    "graph1.add_edge(\"add_hello\", \"add_world\")\n",
    "graph1.add_edge(\"add_world\", \"add_exclamation\")\n",
    "graph1.add_edge(\"add_exclamation\", END)\n",
    "\n",
    "# Add nodes and edges...\n",
    "graph1.compile()\n",
    "graph1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph1.start_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage._storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Subgraph Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = Graph()\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def start_process():\n",
    "    print(\"Starting main process\")\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_process():\n",
    "    print(\"Ending main process\")\n",
    "\n",
    "\n",
    "# Create subgraph\n",
    "sub_graph = Graph()\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task1():\n",
    "    print(\"Subtask 1\")\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task2():\n",
    "    print(\"Subtask 2\")\n",
    "\n",
    "\n",
    "# Add edges to subgraph\n",
    "sub_graph.add_edge(START, \"sub_task1\")\n",
    "sub_graph.add_edge(\"sub_task1\", \"sub_task2\")\n",
    "sub_graph.add_edge(\"sub_task2\", END)\n",
    "\n",
    "\n",
    "# Add subgraph as a node to main graph\n",
    "@main_graph.subgraph(name=\"processing\")\n",
    "def processing_subgraph():\n",
    "    return sub_graph\n",
    "\n",
    "\n",
    "# Add edges to main graph including the subgraph\n",
    "main_graph.add_edge(START, \"start_process\")\n",
    "main_graph.add_edge(\"start_process\", \"processing\")  # Connect to subgraph\n",
    "main_graph.add_edge(\"processing\", \"end_process\")  # Connect from subgraph\n",
    "main_graph.add_edge(\"end_process\", END)\n",
    "\n",
    "# Compile and visualize\n",
    "main_graph.compile()\n",
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmain_graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Create a subgraph\n",
    "@main_graph.subgraph()\n",
    "def processing_subgraph():\n",
    "    subgraph = Graph(state=state)\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_a(state):\n",
    "        return {\"execution_order\": \"process_a\", \"counter\": 1}\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_b(state):\n",
    "        return {\"execution_order\": \"process_b\", \"counter\": 2}\n",
    "\n",
    "    subgraph.add_edge(START, \"process_a\")\n",
    "    subgraph.add_edge(\"process_a\", \"process_b\")\n",
    "    subgraph.add_edge(\"process_b\", END)\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "# Main graph nodes\n",
    "@main_graph.node()\n",
    "def start_task(state):\n",
    "    return {\"execution_order\": \"start_task\", \"status\": \"started\"}\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_task(state):\n",
    "    return {\"execution_order\": \"end_task\", \"status\": \"completed\"}\n",
    "\n",
    "\n",
    "# Connect main graph\n",
    "main_graph.add_edge(START, \"start_task\")\n",
    "main_graph.add_edge(\"start_task\", \"processing_subgraph\")\n",
    "main_graph.add_edge(\"processing_subgraph\", \"end_task\")\n",
    "main_graph.add_edge(\"end_task\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "def nested_subgraph():\n",
    "    nested = Graph(state=state)\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task(state):\n",
    "        return {\"execution_order\": \"nested_task\", \"counter\": 1}\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task_2(state):\n",
    "        return {\"execution_order\": \"nested_task_2\", \"counter\": 2}\n",
    "\n",
    "    nested.add_edge(START, \"nested_task\")\n",
    "    nested.add_edge(\"nested_task\", \"nested_task_2\")\n",
    "    nested.add_edge(\"nested_task_2\", END)\n",
    "    return nested\n",
    "\n",
    "\n",
    "# Create parent subgraph containing nested subgraph\n",
    "@main_graph.subgraph()\n",
    "def parent_subgraph():\n",
    "    parent = Graph(state=state)\n",
    "\n",
    "    @parent.node()\n",
    "    def parent_task(state):\n",
    "        return {\"execution_order\": \"parent_task\", \"counter\": 2}\n",
    "\n",
    "    @parent.subgraph()\n",
    "    def inner_nested():\n",
    "        return nested_subgraph()\n",
    "\n",
    "    parent.add_edge(START, \"parent_task\")\n",
    "    parent.add_edge(\"parent_task\", \"inner_nested\")\n",
    "    parent.add_edge(\"inner_nested\", END)\n",
    "    return parent\n",
    "\n",
    "\n",
    "# Main graph setup\n",
    "@main_graph.node()\n",
    "def main_task(state):\n",
    "    return {\"execution_order\": \"main_task\", \"status\": \"running\"}\n",
    "\n",
    "\n",
    "main_graph.add_edge(START, \"main_task\")\n",
    "main_graph.add_edge(\"main_task\", \"parent_subgraph\")\n",
    "main_graph.add_edge(\"parent_subgraph\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Repeated Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_a():\n",
    "    print(\"Node A\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_b():\n",
    "    print(\"Node B\\n\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_c():\n",
    "    print(\"Node C\")\n",
    "\n",
    "\n",
    "# Add a repeat edge that runs node_b 3 times sequentially\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_repeating_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=False)\n",
    "graph.add_edge(\"node_c\", END)\n",
    "\n",
    "# Or run in parallel\n",
    "# graph.add_repeat_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=True)\n",
    "\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 (async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    execution_times: History[float]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "state = StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Simulate CPU-intensive work\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_parallel\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create parallel execution with many repetitions\n",
    "graph.add_edge(START, \"start_task\")\n",
    "graph.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=True\n",
    ")\n",
    "graph.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph.start_async()\n",
    "parallel_time = time.time() - start_time\n",
    "print(f\"Parallel execution time: {parallel_time}\")\n",
    "\n",
    "# Now test sequential execution\n",
    "graph2 = Graph(\n",
    "    state=StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    ")\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Same task as above\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_sequential\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "graph2.add_edge(START, \"start_task\")\n",
    "graph2.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=False\n",
    ")\n",
    "graph2.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph2.start_async()\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "# Parallel execution should be significantly faster\n",
    "assert parallel_time < sequential_time * 0.7  # At least 30% faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_time, sequential_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Router Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_a\"\n",
    "    return \"route_b\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    return {\"result\": {\"result\": \"from route B2\"}, \"execution_order\": \"route_b2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_edge(\"route_b2\", \"route_c\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()  # Will pause after process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._update_execution_plan(\n",
    "    \"process_data\", graph.router_paths[\"process_data\"][\"route_a\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths[\"process_data\"][\"route_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values {'route_a', 'route_b'}\n",
      "return_values {'route_d', 'route_c'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tiny_graph.graph.executable.Graph at 0x1069d1150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_a\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    if True:\n",
    "        return \"route_c\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "# graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_router_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:tiny_graph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:Executing task in node: process_data\n",
      "DEBUG:tiny_graph.graph.executable:node_name process_data\n",
      "DEBUG:tiny_graph.graph.executable:execution_id exec_a80f6da1\n",
      "DEBUG:tiny_graph.graph.executable:Chain status: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:execution plan: [ExecutableNode(node_name='process_data', task_list=[<function process_data at 0x1069ba200>], node_list=['process_data'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_(route_a_route_a2)_(route_b_route_b2)', task_list=[ExecutableNode(node_name='group_route_a_route_a2', task_list=[<function route_a at 0x1069ba2a0>, <function route_a2 at 0x1069ba520>], node_list=['route_a', 'route_a2'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_route_b_route_b2', task_list=[<function route_b at 0x1069ba3e0>, <function route_b2 at 0x1069ba660>], node_list=['route_b', 'route_b2'], execution_type='sequential', interrupt=None)], node_list=[['route_a', 'route_a2'], ['route_b', 'route_b2']], execution_type='parallel', interrupt=None), ExecutableNode(node_name='route_c', task_list=[<function route_c at 0x1069ba7a0>], node_list=['route_c'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='route_d', task_list=[<function route_d at 0x1069ba8e0>], node_list=['route_d'], execution_type='sequential', interrupt=None)]\n",
      "DEBUG:tiny_graph.graph.executable:Router process_data chose path: ['route_a', 'route_a2', 'route_c']\n",
      "DEBUG:tiny_graph.graph.executable:Updated execution path: [('__start__', 'process_data'), [[('process_data', 'route_a'), ('route_a2', 'route_a2')]], ('process_data', 'route_c'), ('route_c', 'route_d')]\n",
      "DEBUG:tiny_graph.graph.executable:Next node to execute: route_a\n",
      "DEBUG:tiny_graph.graph.executable:starting_new_execution from strach\n",
      "DEBUG:tiny_graph.graph.executable:Chain status updated to: ChainStatus.ROUTING\n",
      "DEBUG:tiny_graph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: process_data\n",
      "DEBUG:tiny_graph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:Executing task in node: route_a\n",
      "DEBUG:tiny_graph.graph.executable:node_name route_a\n",
      "DEBUG:tiny_graph.graph.executable:execution_id exec_08642d76\n",
      "DEBUG:tiny_graph.graph.executable:Chain status: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:execution plan: [ExecutableNode(node_name='process_data', task_list=[<function process_data at 0x1069ba200>], node_list=['process_data'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_(route_a_route_a2)', task_list=[ExecutableNode(node_name='group_route_a_route_a2', task_list=[<function route_a at 0x1069ba2a0>, <function route_a2 at 0x1069ba520>], node_list=['route_a', 'route_a2'], execution_type='sequential', interrupt=None)], node_list=[['route_a', 'route_a2']], execution_type='parallel', interrupt=None), ExecutableNode(node_name='route_c', task_list=[<function route_c at 0x1069ba7a0>], node_list=['route_c'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='route_d', task_list=[<function route_d at 0x1069ba8e0>], node_list=['route_d'], execution_type='sequential', interrupt=None)]\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: group_(route_a_route_a2)\n",
      "DEBUG:tiny_graph.graph.executable:Executing task in node: route_a2\n",
      "DEBUG:tiny_graph.graph.executable:node_name route_a2\n",
      "DEBUG:tiny_graph.graph.executable:execution_id exec_08642d76\n",
      "DEBUG:tiny_graph.graph.executable:Chain status: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:execution plan: [ExecutableNode(node_name='process_data', task_list=[<function process_data at 0x1069ba200>], node_list=['process_data'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_(route_a_route_a2)', task_list=[ExecutableNode(node_name='group_route_a_route_a2', task_list=[<function route_a at 0x1069ba2a0>, <function route_a2 at 0x1069ba520>], node_list=['route_a', 'route_a2'], execution_type='sequential', interrupt=None)], node_list=[['route_a', 'route_a2']], execution_type='parallel', interrupt=None), ExecutableNode(node_name='route_c', task_list=[<function route_c at 0x1069ba7a0>], node_list=['route_c'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='route_d', task_list=[<function route_d at 0x1069ba8e0>], node_list=['route_d'], execution_type='sequential', interrupt=None)]\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: group_(route_a_route_a2)\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: group_(route_a_route_a2)\n",
      "DEBUG:tiny_graph.graph.executable:Executing task in node: route_c\n",
      "DEBUG:tiny_graph.graph.executable:node_name route_c\n",
      "DEBUG:tiny_graph.graph.executable:execution_id exec_08642d76\n",
      "DEBUG:tiny_graph.graph.executable:Chain status: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:execution plan: [ExecutableNode(node_name='process_data', task_list=[<function process_data at 0x1069ba200>], node_list=['process_data'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_(route_a_route_a2)', task_list=[ExecutableNode(node_name='group_route_a_route_a2', task_list=[<function route_a at 0x1069ba2a0>, <function route_a2 at 0x1069ba520>], node_list=['route_a', 'route_a2'], execution_type='sequential', interrupt=None)], node_list=[['route_a', 'route_a2']], execution_type='parallel', interrupt=None), ExecutableNode(node_name='route_c', task_list=[<function route_c at 0x1069ba7a0>], node_list=['route_c'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='route_d', task_list=[<function route_d at 0x1069ba8e0>], node_list=['route_d'], execution_type='sequential', interrupt=None)]\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: route_c\n",
      "DEBUG:tiny_graph.graph.executable:Executing task in node: route_d\n",
      "DEBUG:tiny_graph.graph.executable:node_name route_d\n",
      "DEBUG:tiny_graph.graph.executable:execution_id exec_08642d76\n",
      "DEBUG:tiny_graph.graph.executable:Chain status: ChainStatus.RUNNING\n",
      "DEBUG:tiny_graph.graph.executable:execution plan: [ExecutableNode(node_name='process_data', task_list=[<function process_data at 0x1069ba200>], node_list=['process_data'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='group_(route_a_route_a2)', task_list=[ExecutableNode(node_name='group_route_a_route_a2', task_list=[<function route_a at 0x1069ba2a0>, <function route_a2 at 0x1069ba520>], node_list=['route_a', 'route_a2'], execution_type='sequential', interrupt=None)], node_list=[['route_a', 'route_a2']], execution_type='parallel', interrupt=None), ExecutableNode(node_name='route_c', task_list=[<function route_c at 0x1069ba7a0>], node_list=['route_c'], execution_type='sequential', interrupt=None), ExecutableNode(node_name='route_d', task_list=[<function route_d at 0x1069ba8e0>], node_list=['route_d'], execution_type='sequential', interrupt=None)]\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: route_d\n",
      "DEBUG:tiny_graph.graph.executable:Checkpoint saved after node: process_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing process_data\n",
      "Executing route_a\n",
      "Executing route_a2\n",
      "Executing route_c\n",
      "Executing route_d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'chain_c1dc2595-630c-44a4-8451-5ceeae8882e0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.backend.piping.pipe(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.backend.rendering.render(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.backend.unflattening.unflatten(['stagger', 'fanout', 'chain', 'encoding'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.backend.viewing.view(['quiet'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.quoting.quote(['is_html_string', 'is_valid_id', 'dot_keywords', 'endswith_odd_number_of_backslashes', 'escape_unescaped_quotes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.quoting.a_list(['kwargs', 'attributes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.quoting.attr_list(['kwargs', 'attributes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.clear(['keep_attrs'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.__iter__(['subgraph'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.node(['_attributes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.edge(['_attributes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.attr(['_attributes'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.dot.Dot.subgraph(['name', 'comment', 'graph_attr', 'node_attr', 'edge_attr', 'body'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.piping.Pipe._pipe_legacy(['renderer', 'formatter', 'neato_no_op', 'quiet'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.saving.Save.save(['directory'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.rendering.Render.render(['directory', 'view', 'cleanup', 'format', 'renderer', 'formatter', 'neato_no_op', 'quiet', 'quiet_view'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.rendering.Render.view(['directory', 'cleanup', 'quiet', 'quiet_view'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.unflattening.Unflatten.unflatten(['stagger', 'fanout', 'chain'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.graphs.BaseGraph.__init__(['comment', 'filename', 'directory', 'format', 'engine', 'encoding', 'graph_attr', 'node_attr', 'edge_attr', 'body', 'strict'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.sources.Source.from_file(['directory', 'format', 'engine', 'encoding', 'renderer', 'formatter'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.sources.Source.__init__(['filename', 'directory', 'format', 'engine', 'encoding'])\n",
      "DEBUG:graphviz._tools:deprecate positional args: graphviz.sources.Source.save(['directory'])\n",
      "DEBUG:graphviz.backend.execute:run [PosixPath('dot'), '-Kdot', '-Tsvg']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"963pt\" height=\"106pt\"\n",
       " viewBox=\"0.00 0.00 962.69 106.15\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 102.15)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-102.15 958.69,-102.15 958.69,4 -4,4\"/>\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"47.95\" cy=\"-51.15\" rx=\"47.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.95\" y=\"-48.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__start__</text>\n",
       "</g>\n",
       "<!-- process_data -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>process_data</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M225.07,-66.74C225.07,-66.74 163.12,-53.63 163.12,-53.63 157.25,-52.39 157.25,-49.91 163.12,-48.67 163.12,-48.67 225.07,-35.56 225.07,-35.56 230.94,-34.32 242.68,-34.32 248.55,-35.56 248.55,-35.56 310.49,-48.67 310.49,-48.67 316.36,-49.91 316.36,-52.39 310.49,-53.63 310.49,-53.63 248.55,-66.74 248.55,-66.74 242.68,-67.98 230.94,-67.98 225.07,-66.74\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M225.07,-70.84C225.07,-70.84 143.72,-53.63 143.72,-53.63 137.85,-52.39 137.85,-49.91 143.72,-48.67 143.72,-48.67 225.07,-31.46 225.07,-31.46 230.94,-30.22 242.68,-30.22 248.55,-31.46 248.55,-31.46 329.89,-48.67 329.89,-48.67 335.76,-49.91 335.76,-52.39 329.89,-53.63 329.89,-53.63 248.55,-70.84 248.55,-70.84 242.68,-72.09 230.94,-72.09 225.07,-70.84\"/>\n",
       "<text text-anchor=\"middle\" x=\"236.81\" y=\"-48.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">process_data</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;process_data -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;process_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.1,-51.15C104.11,-51.15 112.73,-51.15 121.62,-51.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.74,-54.65 131.74,-51.15 121.74,-47.65 121.74,-54.65\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"909.52\" cy=\"-45.15\" rx=\"45.34\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"909.52\" y=\"-42.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__end__</text>\n",
       "</g>\n",
       "<!-- route_a -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>route_a</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M426.72,-97.15C426.72,-97.15 389.72,-97.15 389.72,-97.15 383.72,-97.15 377.72,-91.15 377.72,-85.15 377.72,-85.15 377.72,-73.15 377.72,-73.15 377.72,-67.15 383.72,-61.15 389.72,-61.15 389.72,-61.15 426.72,-61.15 426.72,-61.15 432.72,-61.15 438.72,-67.15 438.72,-73.15 438.72,-73.15 438.72,-85.15 438.72,-85.15 438.72,-91.15 432.72,-97.15 426.72,-97.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.22\" y=\"-76.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_a</text>\n",
       "</g>\n",
       "<!-- process_data&#45;&gt;route_a -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>process_data&#45;&gt;route_a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.11,-60.79C319.63,-64.68 346.17,-69.06 367.42,-72.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.95,-76.04 377.38,-74.22 368.09,-69.14 366.95,-76.04\"/>\n",
       "</g>\n",
       "<!-- route_b -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>route_b</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M426.72,-42.15C426.72,-42.15 389.72,-42.15 389.72,-42.15 383.72,-42.15 377.72,-36.15 377.72,-30.15 377.72,-30.15 377.72,-18.15 377.72,-18.15 377.72,-12.15 383.72,-6.15 389.72,-6.15 389.72,-6.15 426.72,-6.15 426.72,-6.15 432.72,-6.15 438.72,-12.15 438.72,-18.15 438.72,-18.15 438.72,-30.15 438.72,-30.15 438.72,-36.15 432.72,-42.15 426.72,-42.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.22\" y=\"-21.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_b</text>\n",
       "</g>\n",
       "<!-- process_data&#45;&gt;route_b -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>process_data&#45;&gt;route_b</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.06,-41.71C320.24,-38.01 346.22,-33.87 367.13,-30.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.93,-33.96 377.26,-28.93 366.83,-27.04 367.93,-33.96\"/>\n",
       "</g>\n",
       "<!-- route_a2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>route_a2</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M575.53,-98.15C575.53,-98.15 533.53,-98.15 533.53,-98.15 527.53,-98.15 521.53,-92.15 521.53,-86.15 521.53,-86.15 521.53,-74.15 521.53,-74.15 521.53,-68.15 527.53,-62.15 533.53,-62.15 533.53,-62.15 575.53,-62.15 575.53,-62.15 581.53,-62.15 587.53,-68.15 587.53,-74.15 587.53,-74.15 587.53,-86.15 587.53,-86.15 587.53,-92.15 581.53,-98.15 575.53,-98.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"554.53\" y=\"-77.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_a2</text>\n",
       "</g>\n",
       "<!-- route_a&#45;&gt;route_a2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>route_a&#45;&gt;route_a2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M438.77,-79.36C459.65,-79.5 487.95,-79.7 511.22,-79.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"511.49,-83.36 521.51,-79.93 511.54,-76.36 511.49,-83.36\"/>\n",
       "</g>\n",
       "<!-- route_b2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>route_b2</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M542.98,-37.04C542.98,-37.04 501.38,-25.39 501.38,-25.39 495.6,-23.77 495.6,-20.53 501.38,-18.91 501.38,-18.91 542.98,-7.26 542.98,-7.26 548.76,-5.65 560.31,-5.65 566.09,-7.26 566.09,-7.26 607.69,-18.91 607.69,-18.91 613.47,-20.53 613.47,-23.77 607.69,-25.39 607.69,-25.39 566.09,-37.04 566.09,-37.04 560.31,-38.66 548.76,-38.66 542.98,-37.04\"/>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M542.98,-41.22C542.98,-41.22 486.45,-25.39 486.45,-25.39 480.68,-23.77 480.68,-20.53 486.45,-18.91 486.45,-18.91 542.98,-3.08 542.98,-3.08 548.76,-1.47 560.31,-1.47 566.09,-3.08 566.09,-3.08 622.61,-18.91 622.61,-18.91 628.39,-20.53 628.39,-23.77 622.61,-25.39 622.61,-25.39 566.09,-41.22 566.09,-41.22 560.31,-42.84 548.76,-42.84 542.98,-41.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"554.53\" y=\"-19.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_b2</text>\n",
       "</g>\n",
       "<!-- route_b&#45;&gt;route_b2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>route_b&#45;&gt;route_b2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M438.77,-23.74C447.58,-23.62 457.71,-23.48 468.23,-23.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"468.45,-26.83 478.4,-23.19 468.35,-19.83 468.45,-26.83\"/>\n",
       "</g>\n",
       "<!-- route_c -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>route_c</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M719.35,-86.15C719.35,-86.15 682.35,-86.15 682.35,-86.15 676.35,-86.15 670.35,-80.15 670.35,-74.15 670.35,-74.15 670.35,-62.15 670.35,-62.15 670.35,-56.15 676.35,-50.15 682.35,-50.15 682.35,-50.15 719.35,-50.15 719.35,-50.15 725.35,-50.15 731.35,-56.15 731.35,-62.15 731.35,-62.15 731.35,-74.15 731.35,-74.15 731.35,-80.15 725.35,-86.15 719.35,-86.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"700.85\" y=\"-65.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_c</text>\n",
       "</g>\n",
       "<!-- route_a2&#45;&gt;route_c -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>route_a2&#45;&gt;route_c</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M587.56,-77.49C608.88,-75.72 637.04,-73.37 659.83,-71.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"660.21,-74.96 669.88,-70.64 659.63,-67.98 660.21,-74.96\"/>\n",
       "</g>\n",
       "<!-- route_b2&#45;&gt;route_c -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>route_b2&#45;&gt;route_c</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M592.32,-33.88C613.09,-40.5 639.04,-48.77 660.25,-55.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"659.34,-58.91 669.93,-58.61 661.46,-52.24 659.34,-58.91\"/>\n",
       "</g>\n",
       "<!-- route_d -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>route_d</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M816.35,-63.15C816.35,-63.15 779.35,-63.15 779.35,-63.15 773.35,-63.15 767.35,-57.15 767.35,-51.15 767.35,-51.15 767.35,-39.15 767.35,-39.15 767.35,-33.15 773.35,-27.15 779.35,-27.15 779.35,-27.15 816.35,-27.15 816.35,-27.15 822.35,-27.15 828.35,-33.15 828.35,-39.15 828.35,-39.15 828.35,-51.15 828.35,-51.15 828.35,-57.15 822.35,-63.15 816.35,-63.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"797.85\" y=\"-42.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">route_d</text>\n",
       "</g>\n",
       "<!-- route_b2&#45;&gt;route_d -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>route_b2&#45;&gt;route_d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.26,-27.75C658.51,-31.97 718.01,-37.64 756.88,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"756.98,-44.87 767.27,-42.33 757.64,-37.9 756.98,-44.87\"/>\n",
       "</g>\n",
       "<!-- route_c&#45;&gt;route_d -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>route_c&#45;&gt;route_d</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M731.39,-61C739.61,-59.01 748.67,-56.82 757.37,-54.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"758.44,-58.05 767.33,-52.3 756.79,-51.25 758.44,-58.05\"/>\n",
       "</g>\n",
       "<!-- route_d&#45;&gt;__end__ -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>route_d&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M828.53,-45.15C836.37,-45.15 845.09,-45.15 853.8,-45.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"853.98,-48.65 863.98,-45.15 853.98,-41.65 853.98,-48.65\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x106affdd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._update_execution_plan(\"process_data\", \"route_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._convert_execution_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "x = [\n",
    "    \"process_data\",\n",
    "    [[\"route_b\", \"route_b2\"], [\"route_a\", \"route_a2\", \"route_c\"]],\n",
    "    \"route_d\",\n",
    "]\n",
    "\n",
    "x2 = [\n",
    "    \"process_data\",\n",
    "    [[[\"route_b\", \"route_b2\"]], [\"route_a\", \"route_a2\", \"route_c\"]],\n",
    "    \"route_d\",\n",
    "]\n",
    "\n",
    "\n",
    "def update_execution_path(path: List[Any], chosen_node: str) -> List[Any]:\n",
    "    new_path = []\n",
    "    found_router = False\n",
    "\n",
    "    def isolate_chosen_path(chosen_node: str, path: List[Any]) -> List[Any]:\n",
    "        for item in path:\n",
    "            if isinstance(item, (tuple, list)):\n",
    "                isolate_chosen_path(chosen_node, item)\n",
    "            else:\n",
    "                if item == chosen_node:\n",
    "                    return path\n",
    "            return None\n",
    "\n",
    "    for item in path:\n",
    "        if isolate_chosen_path(chosen_node, item):\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "\n",
    "print(update_execution_path(x[1], \"route_a\"))\n",
    "print(update_execution_path(x2[1], \"route_a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._convert_execution_plan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.router_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    if True:\n",
    "        return \"route_d\"\n",
    "    return \"route_b\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(START, \"route_a\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_b\")\n",
    "graph.add_router_edge(\"route_b\", \"route_c\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
