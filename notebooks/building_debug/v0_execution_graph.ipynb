{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "\n",
    "from primeGraph.buffer.factory import History, Incremental, LastValue\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution plan conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    print(\"g \\n\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"b\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"c\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"e\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    time.sleep(1)\n",
    "    print(\"g\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"c\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"e\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "# Create a test graph with a mix of parallel and sequential paths\n",
    "test_graph = Graph()\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def start_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting workflow \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_1():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 1 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 1 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_2():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 2 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 2 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def final_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Running final task \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# Create a workflow with parallel execution\n",
    "test_graph.add_edge(START, \"start_task\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_1\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_2\")\n",
    "test_graph.add_edge(\"parallel_task_1\", \"final_task\")\n",
    "test_graph.add_edge(\"parallel_task_2\", \"final_task\")\n",
    "test_graph.add_edge(\"final_task\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "print(\"\\nExecution Plan:\")\n",
    "rprint(test_graph.execution_plan)\n",
    "print(\"\\nStarting execution:\")\n",
    "start_time = time.time()\n",
    "test_graph.execute()\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node()\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(f\"Counter: {test_graph.state.counter}\")  # Should be 8 (5 + 3)\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should contain both metric updates\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.constants import END, START\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@test_graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_status(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "# Create the workflow with parallel execution\n",
    "test_graph.add_edge(START, \"increment_counter\")\n",
    "test_graph.add_edge(START, \"decrement_counter\")\n",
    "test_graph.add_edge(START, \"update_status\")\n",
    "test_graph.add_edge(\"increment_counter\", END)\n",
    "test_graph.add_edge(\"decrement_counter\", END)\n",
    "test_graph.add_edge(\"update_status\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(\n",
    "    f\"Counter: {test_graph.state.counter}\"\n",
    ")  # Should reflect the net effect of increments and decrements\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should be empty as no metrics are updated\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"in_progress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(\"process_data\", \"validate\")\n",
    "graph.add_edge(\"validate\", \"escape\")\n",
    "graph.add_edge(\"escape\", \"prep\")\n",
    "graph.add_edge(\"validate\", \"aa\")\n",
    "graph.add_edge(\"aa\", \"bb\")\n",
    "graph.add_edge(\"bb\", \"prep\")\n",
    "graph.add_edge(\"prep\", END)\n",
    "\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "\n",
    "\n",
    "graph.start(timeout=10)\n",
    "\n",
    "rprint(graph.state)\n",
    "\n",
    "# Assert final state\n",
    "assert (\n",
    "    graph.state.counter == 1\n",
    "), \"Counter should reflect net effect of increments and decrements\"\n",
    "assert graph.state.status == \"complete\", \"Status should be 'complete'\"\n",
    "assert len(graph.state.metrics) == 3, \"Metrics should contain three updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={\"xablau\": 2.0})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"counter\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"metrics\"].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(simple_graph._convert_execution_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_execution_plan(plan, metadata):\n",
    "    def slice_list(lst, meta):\n",
    "        result = []\n",
    "        for item in lst:\n",
    "            if isinstance(item, list):\n",
    "                # Recursively slice nested lists\n",
    "                sliced_item = slice_list(item, meta)\n",
    "                if sliced_item:\n",
    "                    result.append(sliced_item)\n",
    "            else:\n",
    "                # Check metadata for slicing\n",
    "                if meta.get(item) == \"before\":\n",
    "                    break\n",
    "                result.append(item)\n",
    "                if meta.get(item) == \"after\":\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    return slice_list(plan, metadata)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "execution_plan = [\n",
    "    \"process_data\",\n",
    "    \"validate\",\n",
    "    [[\"escape\", [\"dd\", \"cc\"], \"hh\"], [\"aa\", \"bb\"]],\n",
    "    \"prep\",\n",
    "]\n",
    "metadata = {\n",
    "    # 'process_data': 'after',\n",
    "    # 'validate': 'before',\n",
    "    # 'escape': 'after',\n",
    "    \"dd\": \"before\",\n",
    "    # 'cc': 'after',\n",
    "    # 'hh': 'before',\n",
    "    # 'aa': 'after',\n",
    "    # 'bb': 'before',\n",
    "    # 'prep': 'after'\n",
    "}\n",
    "\n",
    "sliced_plan = slice_execution_plan(execution_plan, metadata)\n",
    "print(sliced_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_plan[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem here is that in the case of update_status_to_complete,\n",
    "# it's not checking if the next node is a convergence point\n",
    "\n",
    "# it needs to have a function that will check if the next node\n",
    "# connector. find_convergence_point is not doing enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing interruption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = escape\n",
    "\n",
    "x.__metadata__[\"interrupt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    time.sleep(0.5)\n",
    "    print(\"escape\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    time.sleep(1.5)\n",
    "    print(\"process_data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    time.sleep(0.5)\n",
    "    print(\"validate\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    time.sleep(1.5)\n",
    "    print(\"aa\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    time.sleep(0.5)\n",
    "    print(\"bb\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    time.sleep(1.5)\n",
    "    print(\"dd\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    time.sleep(1.5)\n",
    "    print(\"cc\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    time.sleep(0.5)\n",
    "    print(\"hh\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    time.sleep(0.5)\n",
    "    print(\"prep\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "simple_graph._convert_execution_plan()\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.graph.executable import ExecutableNode\n",
    "\n",
    "\n",
    "def add_item_to_obj_store(obj_store: Union[List, Tuple], item):\n",
    "    if isinstance(obj_store, list):\n",
    "        obj_store.append(item)\n",
    "        return obj_store  # Return the modified list\n",
    "    elif isinstance(obj_store, tuple):\n",
    "        return obj_store + (item,)  # Already returns the new tuple\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object store type: {type(obj_store)}\")\n",
    "\n",
    "\n",
    "def extract_tasks_from_node(node, tasks=[]):\n",
    "    \"\"\"\n",
    "    Extracts tasks from a node, including nested nodes\n",
    "    returns lists for sequential execution and tuples for parallel execution\n",
    "    \"\"\"\n",
    "    tasks = [] if node.execution_type == \"sequential\" else tuple()\n",
    "    for task in node.task_list:\n",
    "        if isinstance(task, ExecutableNode):\n",
    "            if task.execution_type == \"sequential\":\n",
    "                tasks = add_item_to_obj_store(tasks, extract_tasks_from_node(task, []))\n",
    "            else:\n",
    "                tasks = add_item_to_obj_store(\n",
    "                    tasks, extract_tasks_from_node(task, tuple())\n",
    "                )\n",
    "        else:\n",
    "            tasks = add_item_to_obj_store(tasks, task)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "rprint(extract_tasks_from_node(simple_graph.execution_plan[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=0, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"increment_counter\")\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"decrement_counter\")\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_in_progress\")\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_complete\")\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"finalize_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "graph._convert_execution_plan()\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def task2(state):\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task3(state):\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[edge.id for edge in graph.edges if edge.end_node == \"__start__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Async Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 (testing non-async using execute_async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics=[], current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "def step_1():\n",
    "    time.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_A():\n",
    "    time.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_B():\n",
    "    time.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_2():\n",
    "    time.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "async def step_1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_A():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_B():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_2():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task1(state):\n",
    "    print(\"task1\")\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task2(state):\n",
    "    print(\"task2\")\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "async def task3(state):\n",
    "    print(\"task3\")\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task4(state):\n",
    "    print(\"task4\")\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "# Create parallel paths\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task1\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()\n",
    "\n",
    "# First execution should execute task1 and task3, but pause before task2\n",
    "# await graph.start_async()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "StateForTestWithHistory(execution_order=[\"a\", 2], counter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "ComplexTestState(counter=0, status=\"\", metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "class SimpleGraphState(GraphState):\n",
    "    messages: History[str]\n",
    "\n",
    "\n",
    "# Create state instance\n",
    "state = SimpleGraphState(messages=[])\n",
    "\n",
    "# Update graph with state\n",
    "storage = LocalStorage()\n",
    "graph1 = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_hello(state: GraphState):\n",
    "    return {\"messages\": \"Hello\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_world(state: GraphState):\n",
    "    return {\"messages\": \"World\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_exclamation(state: GraphState):\n",
    "    return {\"messages\": \"!\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "graph1.add_edge(START, \"add_hello\")\n",
    "graph1.add_edge(\"add_hello\", \"add_world\")\n",
    "graph1.add_edge(\"add_world\", \"add_exclamation\")\n",
    "graph1.add_edge(\"add_exclamation\", END)\n",
    "\n",
    "# Add nodes and edges...\n",
    "graph1.compile()\n",
    "graph1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph1.start_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage._storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Subgraph Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = Graph()\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def start_process():\n",
    "    print(\"Starting main process\")\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_process():\n",
    "    print(\"Ending main process\")\n",
    "\n",
    "\n",
    "# Create subgraph\n",
    "sub_graph = Graph()\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task1():\n",
    "    print(\"Subtask 1\")\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task2():\n",
    "    print(\"Subtask 2\")\n",
    "\n",
    "\n",
    "# Add edges to subgraph\n",
    "sub_graph.add_edge(START, \"sub_task1\")\n",
    "sub_graph.add_edge(\"sub_task1\", \"sub_task2\")\n",
    "sub_graph.add_edge(\"sub_task2\", END)\n",
    "\n",
    "\n",
    "# Add subgraph as a node to main graph\n",
    "@main_graph.subgraph(name=\"processing\")\n",
    "def processing_subgraph():\n",
    "    return sub_graph\n",
    "\n",
    "\n",
    "# Add edges to main graph including the subgraph\n",
    "main_graph.add_edge(START, \"start_process\")\n",
    "main_graph.add_edge(\"start_process\", \"processing\")  # Connect to subgraph\n",
    "main_graph.add_edge(\"processing\", \"end_process\")  # Connect from subgraph\n",
    "main_graph.add_edge(\"end_process\", END)\n",
    "\n",
    "# Compile and visualize\n",
    "main_graph.compile()\n",
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmain_graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Create a subgraph\n",
    "@main_graph.subgraph()\n",
    "def processing_subgraph():\n",
    "    subgraph = Graph(state=state)\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_a(state):\n",
    "        return {\"execution_order\": \"process_a\", \"counter\": 1}\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_b(state):\n",
    "        return {\"execution_order\": \"process_b\", \"counter\": 2}\n",
    "\n",
    "    subgraph.add_edge(START, \"process_a\")\n",
    "    subgraph.add_edge(\"process_a\", \"process_b\")\n",
    "    subgraph.add_edge(\"process_b\", END)\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "# Main graph nodes\n",
    "@main_graph.node()\n",
    "def start_task(state):\n",
    "    return {\"execution_order\": \"start_task\", \"status\": \"started\"}\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_task(state):\n",
    "    return {\"execution_order\": \"end_task\", \"status\": \"completed\"}\n",
    "\n",
    "\n",
    "# Connect main graph\n",
    "main_graph.add_edge(START, \"start_task\")\n",
    "main_graph.add_edge(\"start_task\", \"processing_subgraph\")\n",
    "main_graph.add_edge(\"processing_subgraph\", \"end_task\")\n",
    "main_graph.add_edge(\"end_task\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "def nested_subgraph():\n",
    "    nested = Graph(state=state)\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task(state):\n",
    "        return {\"execution_order\": \"nested_task\", \"counter\": 1}\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task_2(state):\n",
    "        return {\"execution_order\": \"nested_task_2\", \"counter\": 2}\n",
    "\n",
    "    nested.add_edge(START, \"nested_task\")\n",
    "    nested.add_edge(\"nested_task\", \"nested_task_2\")\n",
    "    nested.add_edge(\"nested_task_2\", END)\n",
    "    return nested\n",
    "\n",
    "\n",
    "# Create parent subgraph containing nested subgraph\n",
    "@main_graph.subgraph()\n",
    "def parent_subgraph():\n",
    "    parent = Graph(state=state)\n",
    "\n",
    "    @parent.node()\n",
    "    def parent_task(state):\n",
    "        return {\"execution_order\": \"parent_task\", \"counter\": 2}\n",
    "\n",
    "    @parent.subgraph()\n",
    "    def inner_nested():\n",
    "        return nested_subgraph()\n",
    "\n",
    "    parent.add_edge(START, \"parent_task\")\n",
    "    parent.add_edge(\"parent_task\", \"inner_nested\")\n",
    "    parent.add_edge(\"inner_nested\", END)\n",
    "    return parent\n",
    "\n",
    "\n",
    "# Main graph setup\n",
    "@main_graph.node()\n",
    "def main_task(state):\n",
    "    return {\"execution_order\": \"main_task\", \"status\": \"running\"}\n",
    "\n",
    "\n",
    "main_graph.add_edge(START, \"main_task\")\n",
    "main_graph.add_edge(\"main_task\", \"parent_subgraph\")\n",
    "main_graph.add_edge(\"parent_subgraph\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Repeated Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_a():\n",
    "    print(\"Node A\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_b():\n",
    "    print(\"Node B\\n\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_c():\n",
    "    print(\"Node C\")\n",
    "\n",
    "\n",
    "# Add a repeat edge that runs node_b 3 times sequentially\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_repeating_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=False)\n",
    "graph.add_edge(\"node_c\", END)\n",
    "\n",
    "# Or run in parallel\n",
    "# graph.add_repeat_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=True)\n",
    "\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 (async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    execution_times: History[float]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "state = StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Simulate CPU-intensive work\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_parallel\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create parallel execution with many repetitions\n",
    "graph.add_edge(START, \"start_task\")\n",
    "graph.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=True\n",
    ")\n",
    "graph.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph.start_async()\n",
    "parallel_time = time.time() - start_time\n",
    "print(f\"Parallel execution time: {parallel_time}\")\n",
    "\n",
    "# Now test sequential execution\n",
    "graph2 = Graph(\n",
    "    state=StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    ")\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Same task as above\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_sequential\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "graph2.add_edge(START, \"start_task\")\n",
    "graph2.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=False\n",
    ")\n",
    "graph2.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph2.start_async()\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "# Parallel execution should be significantly faster\n",
    "assert parallel_time < sequential_time * 0.7  # At least 30% faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_time, sequential_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Router Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "storage = LocalStorage()\n",
    "graph = Graph(\n",
    "    state=TestState(result={}, execution_order=[]), checkpoint_storage=storage\n",
    ")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_a\"\n",
    "    return \"route_b\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    return {\"result\": {\"result\": \"from route B2\"}, \"execution_order\": \"route_b2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_edge(\"route_b2\", \"route_c\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()  # Will pause after process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._update_execution_plan(\n",
    "    \"process_data\", graph.router_paths[\"process_data\"][\"route_a\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths[\"process_data\"][\"route_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_a\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    if True:\n",
    "        return \"route_c\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "# graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_router_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()\n",
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(START, \"route_a\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_b\")\n",
    "graph.add_router_edge(\"route_b\", \"route_c\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.next_execution_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.blocking_execution_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Real World Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical planner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List, Any\n",
    "\n",
    "\n",
    "\n",
    "class State(GraphState):\n",
    "    conversation: History[Dict[str, str]]\n",
    "    model_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]]\n",
    "    is_forward_permission: LastValue[Union[bool, None]]\n",
    "    is_permission_granted: LastValue[Union[bool, None]]\n",
    "    is_outside_of_step: LastValue[Union[bool, None]]\n",
    "    plan_goal: LastValue[str]\n",
    "    plan_summary: LastValue[str]\n",
    "    plan_details: History[str]\n",
    "    is_ready_to_move_forward: LastValue[bool]\n",
    "    is_summary_approved: LastValue[bool]\n",
    "    interaction_summary: LastValue[str]\n",
    "    \n",
    "\n",
    "def generate_plan_graph(graph_state: State):\n",
    "    \n",
    "    plan_graph = Graph(graph_state, verbose=False)\n",
    "    \n",
    "\n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    async def intitialize_conversation(state: State) -> dict[str, Any]:\n",
    "        print(\"Initializing conversation...\")\n",
    "        response = \"Welcome! Please tell me your goal in a single sentence.\"\n",
    "    \n",
    "        \n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    async def process_user_message(state: State) -> dict[str, Any]:\n",
    "        print(\"Processing user message...\")\n",
    "        \n",
    "        # Simulated response\n",
    "        response = \"I understand your goal. Let me ask a follow-up question.\"\n",
    "        plan_goal = \"Sample goal\"\n",
    "        plan_details = [\"Detail 1\", \"Detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        # Add sample plan details\n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"plan_goal\": plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def response_router(state: State) -> str:\n",
    "        print(\"Routing response...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        elif state.is_forward_permission:\n",
    "            return 'summarize_and_ask_permission'\n",
    "        return END\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def make_followup_questions(state: State):\n",
    "        print(\"Making follow-up questions...\")\n",
    "        response = \"Here's a follow-up question for clarification.\"\n",
    "        plan_details = [\"Follow-up detail 1\", \"Follow-up detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def check_followup_next_step(state: State):\n",
    "        print(\"Checking follow-up next step...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        return 'summarize_and_ask_permission'\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def summarize_and_ask_permission(state: State):\n",
    "        print(\"Summarizing and asking for permission...\")\n",
    "        response = \"Here's a summary of our discussion. Shall we move forward?\"\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": False,\n",
    "            \"is_permission_granted\": True,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def move_to_next_step(state: State):\n",
    "        print(\"Moving to next step...\")\n",
    "        if state.is_permission_granted:\n",
    "            return END\n",
    "        return 'process_user_message'\n",
    "\n",
    "\n",
    "    plan_graph.add_edge(START, 'intitialize_conversation')\n",
    "    plan_graph.add_edge('intitialize_conversation', 'process_user_message')\n",
    "    plan_graph.add_router_edge('process_user_message', 'response_router')\n",
    "    plan_graph.add_router_edge('make_followup_questions', 'check_followup_next_step')\n",
    "\n",
    "    plan_graph.add_router_edge(\"summarize_and_ask_permission\", \"move_to_next_step\")\n",
    "    \n",
    "    \n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_graph_state = State(conversation=[], \n",
    "                         model_message=None, \n",
    "                         user_message=None,\n",
    "                         next_interaction={\"worflow_step\": \"user_prompt\"}, \n",
    "                         plan_goal=\"\", \n",
    "                         plan_summary=\"\", \n",
    "                         plan_details=[], \n",
    "                         is_summary_approved=False, \n",
    "                         interaction_summary=\"\", \n",
    "                         is_followup=False,\n",
    "                         is_forward_permission=False,\n",
    "                         is_permission_granted=False,\n",
    "                         is_outside_of_step=False,\n",
    "                         is_ready_to_move_forward=False)\n",
    "\n",
    "graph = generate_plan_graph(plan_graph_state)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.start_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.is_cyclical_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical planner - storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List\n",
    "from primeGraph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "sys_prompt_0 = \"\"\"\n",
    "Give the user a welcome message and ask them to state their goal in a single sentence.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_1 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "\n",
    "Phase 1: Goal Understanding\n",
    "\n",
    "Ask the user to state their goal in a single sentence\n",
    "Have them specify what success looks like for this goal\n",
    "Determine if there are any absolute constraints or requirements\n",
    "\n",
    "If the goal is clear, just say \"Ok, I got it\"\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_2 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "\n",
    "    Phase 2: Information Gathering\n",
    "\n",
    "Ask clarifying questions focusing only on high-level aspects:\n",
    "\n",
    "What are the major components or phases?\n",
    "Who are the key stakeholders?\n",
    "What are the critical dependencies?\n",
    "What resources are already available?\n",
    "\n",
    "\n",
    "For each unclear point:\n",
    "\n",
    "Ask one focused question at a time\n",
    "Avoid diving into implementation details\n",
    "Capture only information relevant to overall structure\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_3 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "Phase 3: Plan Summary & Validation\n",
    "\n",
    "Create a structured summary including:\n",
    "\n",
    "Main goal statement\n",
    "Key success criteria\n",
    "Major components identified\n",
    "Critical dependencies\n",
    "High-level timeline\n",
    "Key stakeholders\n",
    "\n",
    "\n",
    "Present the summary to user:\n",
    "\n",
    "Ask if anything major is missing\n",
    "Confirm if the interpretation is correct\n",
    "Verify if the level of detail is appropriate\n",
    "\n",
    "How to present: \n",
    "\n",
    "- Strucutre things in a way that is easy to understand like: \n",
    "    - Use bullet points\n",
    "    - Use numbered lists\n",
    "    - Use tables\n",
    "    - Use markdown\n",
    "- Make it visually appealing\n",
    "\n",
    "\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "storage = PostgreSQLStorage.from_config(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    user=\"primegraph\",\n",
    "    password=\"primegraph\",\n",
    "    database=\"primegraph\",\n",
    ")\n",
    "\n",
    "class PlannerState(GraphState):\n",
    "    conversation: History[Dict[str, str]] = Field(default_factory=list)\n",
    "    model_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]] = Field(default=None)\n",
    "    is_forward_permission: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_permission_granted: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_outside_of_step: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    plan_goal: LastValue[str] = Field(default=\"\")\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_details: History[str] = Field(default_factory=list)\n",
    "    is_ready_to_move_forward: LastValue[bool] = Field(default=False)\n",
    "    is_summary_approved: LastValue[bool] = Field(default=False)\n",
    "    interaction_summary: LastValue[str] = Field(default=\"\")\n",
    "\n",
    "\n",
    "def planner_graph(graph_state: PlannerState, graph_storage: Union[PostgreSQLStorage, None]) -> Graph:\n",
    "    plan_graph = Graph(state=graph_state, verbose=True, checkpoint_storage=graph_storage)\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def process_user_message(state: PlannerState) -> dict[str, Any]:\n",
    "        class ProcessMessageResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional relevant details of the plan\")\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_forward_permission: bool = Field(description=\"If there are not follow up questions on your end.\")\n",
    "            is_outside_of_step: bool = Field(\n",
    "                description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            )\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=ProcessMessageResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_1},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"plan_goal\": completion.plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_forward_permission\": completion.is_forward_permission,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def response_router(state: PlannerState) -> str:\n",
    "        if state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        elif state.is_forward_permission:\n",
    "            return \"summarize_and_ask_permission\"\n",
    "        return END\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    def make_followup_questions(state: PlannerState):\n",
    "        class FollowupResponse(BaseModel):\n",
    "            plan_details: List[str] = Field(description=\"Any additional you got from your follow up questions\")\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_forward_permission: bool = Field(description=\"If the user is asking to move forward to the next step\")\n",
    "            is_outside_of_step: bool = Field(\n",
    "                description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            )\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FollowupResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_2},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        rprint(completion)\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_forward_permission\": completion.is_forward_permission,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def check_followup_next_step(state: PlannerState):\n",
    "        if state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        else:\n",
    "            return \"summarize_and_ask_permission\"\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    def summarize_and_ask_permission(state: PlannerState):\n",
    "        class PermissionResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_outside_of_step: bool = Field(description=\"If the user is explicitly asking to move to a different step\")\n",
    "            is_permission_granted: bool = Field(description=\"If the user authorized moving to the next step\")\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=PermissionResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_3},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_permission_granted\": completion.is_permission_granted,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def move_to_next_step(state: PlannerState):\n",
    "        if state.is_permission_granted:\n",
    "            return END\n",
    "        else:\n",
    "            return \"process_user_message\"\n",
    "\n",
    "    plan_graph.add_edge(START, \"process_user_message\")\n",
    "    plan_graph.add_router_edge(\"process_user_message\", \"response_router\")\n",
    "    plan_graph.add_router_edge(\"make_followup_questions\", \"check_followup_next_step\")\n",
    "\n",
    "    plan_graph.add_router_edge(\"summarize_and_ask_permission\", \"move_to_next_step\")\n",
    "\n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_graph_state = PlannerState()\n",
    "\n",
    "graph = planner_graph(plan_graph_state, graph_storage=storage)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_id = await graph.start_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I want to plan a wedding party\"})\n",
    "print(\"state_pre_checkpoint\")\n",
    "rprint(graph.state)\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "await graph.resume_async()\n",
    "print(\"state_post_checkpoint\") \n",
    "rprint(graph.state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"sorry lets go back to planning\"})\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "await graph.resume_async()\n",
    "rprint(graph.state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical planner 2- storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "from pydantic import Field\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List\n",
    "from primeGraph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "storage = PostgreSQLStorage.from_config(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    user=\"primegraph\",\n",
    "    password=\"primegraph\",\n",
    "    database=\"primegraph\",\n",
    ")\n",
    "\n",
    "sys_prompt_start = \"\"\"\n",
    "You are a helpful assistant that is able to help the user with their goals.\n",
    "\n",
    "You are part of a workflow for the user to plan for something. This is the first step of the workflow.\n",
    "\n",
    "Give the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\n",
    "\n",
    "- They should share their goal in a clear and concise manner\n",
    "- [OPTIONAL] they should share any relevant context or details about the goal\n",
    "- [OPTIONAL] They should express what success looks like for this goal\n",
    "- [OPTIONAL] They should share any constraints or requirements for the goal\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_process_message = \"\"\"\n",
    "\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow in this is the second (and more important) step.\n",
    "\n",
    "Your goal is to analyze the user's message and route them to the next step in the workflow.\n",
    "\n",
    "You will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Analyze current information about the goal and the conversation history\n",
    "- Assess if the information gathered is enough to create a good plan\n",
    "- Route user to the next step in the workflow\n",
    "- Make sure you capture user's intent and route them to the correct step\n",
    "- Make the user experience seemless and seamless\n",
    "\n",
    "==== WORKFLOW STEPS =====\n",
    "\n",
    "Everything evolve around you capacity to create a good plan in the end. \n",
    "Based on the information gathered, evaluate the following:\n",
    "\n",
    "IF information about the goal, details, or anything that can help you create a good plan is needed:\n",
    "- [Follow up questions]\n",
    "    - Ask follow up questions to gather more information about the goal\n",
    "    - Analyze all the information gathered and judge if addional information is needed\n",
    "    - Be clear and concise with the follow up questions\n",
    "\n",
    "IF all the information is gathered and/or the user is ready to move forward, choose between:\n",
    "- [Summarize and ask permission]: \n",
    "    - Help the user visualize the high level plan\n",
    "    - Share your plan into macro steps with a brief summary of what each step entails\n",
    "    - Check if the user would like to proceed with the next step\n",
    "- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\n",
    "\n",
    "Unrelated:\n",
    "- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\n",
    "\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Pay extreme attention to the user's message\n",
    "- Try to understand the user's intent\n",
    "- Always pick only ONE of the options presented to you on WORKFLOW STEPS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_followup = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a follow up step.\n",
    "\n",
    "Your goal is to analyze the user's goal, the information gathered and the conversation history.\n",
    "Based on the information gathered, you should ask follow up questions to gather more information about the goal.\n",
    "\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Analyze current information\n",
    "- Make additional follow up questions ONLY IF NEEDED\n",
    "    - The act of gather more information should be to make sure that the planning process has its goals achieved\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Pay extreme attention to all the curren information gathered\n",
    "- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\n",
    "- Make follow up questions ONLY IF NEEDED\n",
    "    - The act of gather more information should be to make sure that the planning process has its goals achieved\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_summarize = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a summarize step.\n",
    "\n",
    "Your goal is to share with the user a high level overview of the plan you are about to create.\n",
    "Make it short anc concise, but also include all the important details.\n",
    "Make it visually easy to understand and review (on the user's end). \n",
    "Ask if the user would like to proceed with the next step.\n",
    "\n",
    "\n",
    "__ The main goal for this entire planning process: __\n",
    "\n",
    "- Break down the user goal in the planning steps that are:\n",
    "    - Clear\n",
    "    - Concise\n",
    "    - Easy to understand\n",
    "    - Easy to follow\n",
    "\n",
    "__ The main goal with this step is to: __\n",
    "\n",
    "- Summarize the plan in a way that is easy to understand and review\n",
    "- Make it visually easy to understand and review (on the user's end)\n",
    "- Ask if the user would like to proceed with the next step\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Make sure you include all the important details\n",
    "- Make sure you have a decent break down of the plan\n",
    "- Make it visually easy to understand and review (on the user's end)\n",
    "- Ask if the user would like to proceed with the next step\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_finalize = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are in a planning workflow and this is a finalize step.\n",
    "\n",
    "Your goal is to say goodbye to the user and thank them for using your service.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class PlannerState(GraphState):\n",
    "    conversation: History[Dict[str, str]] = Field(default_factory=list)\n",
    "    model_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]] = Field(default=None)\n",
    "    is_summarize: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_finalize: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_outside_of_the_workflow: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    plan_goal: LastValue[str] = Field(default=\"\")\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_steps: LastValue[List[str]] = Field(default_factory=list)\n",
    "    plan_details: History[str] = Field(default_factory=list)\n",
    "    current_information_assessment: LastValue[str] = Field(default=\"\")\n",
    "    follow_up_questions: LastValue[List[str]] = Field(default_factory=list)\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_steps: LastValue[List[str]] = Field(default_factory=list)\n",
    "\n",
    "def planner_graph(graph_state: PlannerState, checkpoint_storage: Union[PostgreSQLStorage, None]) -> Graph:\n",
    "    plan_graph = Graph(state=graph_state, verbose=True, checkpoint_storage=checkpoint_storage)\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def start_conversation(state: PlannerState) -> dict[str, Any]:\n",
    "        class StartConversationResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=StartConversationResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_start},\n",
    "            ],\n",
    "        )\n",
    "        return {\"conversation\": {\"role\": \"assistant\", \"content\": completion.response}}\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def process_user_message(state: PlannerState) -> dict[str, Any]:\n",
    "        class ProcessMessageResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional relevant details of the plan\")\n",
    "            is_followup: bool # = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_summarize: bool # = Field(description=\"If there are not follow up questions on your end.\")\n",
    "            is_finalize: bool # = Field(\n",
    "            #     description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            # )\n",
    "            is_outside_of_the_workflow: bool # = Field(\n",
    "            #     description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            # )\n",
    "\n",
    "        rprint(\"state before processing user message\")\n",
    "        rprint(state)\n",
    "        # add user message to the conversation\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=ProcessMessageResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_process_message},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        rprint(\"chat completion\")\n",
    "        rprint(completion)\n",
    "\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"plan_goal\": completion.plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": None,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_summarize\": completion.is_summarize,\n",
    "            \"is_finalize\": completion.is_finalize,\n",
    "            \"is_outside_of_the_workflow\": completion.is_outside_of_the_workflow,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def response_router(state: PlannerState) -> str:\n",
    "        if state.is_finalize:\n",
    "            return \"finalize_plan\"\n",
    "        elif state.is_summarize:\n",
    "            return \"summarize_plan\"\n",
    "        elif state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        else:\n",
    "            return \"process_user_message\"\n",
    "                \n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def make_followup_questions(state: PlannerState):\n",
    "        class FollowupResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional you got from your interactions with the user\")\n",
    "            current_information_assessment: str = Field(description=\"A brief assessment of the current information gathered\")\n",
    "            follow_up_questions: List[str] = Field(description=\"The follow up questions that you think are needed to gather more information about the goal\")\n",
    "            response: str = Field(description=\"Your response with the follow up questions\")\n",
    "\n",
    "    \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FollowupResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_followup},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"current_information_assessment\": completion.current_information_assessment,\n",
    "            \"follow_up_questions\": completion.follow_up_questions,\n",
    "        }\n",
    "  \n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    def summarize_plan(state: PlannerState):\n",
    "        class SummarizeResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            plan_summary: str = Field(description=\"A summary of the plan\")\n",
    "            plan_steps: List[str] = Field(description=\"A list of the steps that are part of the plan\")\n",
    "\n",
    "            \n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=SummarizeResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_summarize},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"plan_summary\": completion.plan_summary,\n",
    "            \"plan_steps\": completion.plan_steps,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    def finalize_plan(state: PlannerState):\n",
    "        class FinalizeResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FinalizeResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_finalize},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "        }\n",
    "\n",
    "\n",
    "    plan_graph.add_edge(START, \"start_conversation\")\n",
    "    plan_graph.add_edge(\"start_conversation\", \"process_user_message\")\n",
    "    plan_graph.add_router_edge(\"process_user_message\", \"response_router\")\n",
    "\n",
    "    plan_graph.add_edge(\"summarize_plan\", \"process_user_message\")\n",
    "    plan_graph.add_edge(\"make_followup_questions\", \"process_user_message\")\n",
    "    plan_graph.add_edge(\"finalize_plan\", END)\n",
    "    \n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Patching `client.chat.completions.create` with mode=<Mode.TOOLS: 'tool_call'>\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"568pt\" height=\"489pt\"\n",
       " viewBox=\"21.60 21.60 546.83 467.31\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(25.6 463.31)\">\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"278.93\" cy=\"-419.58\" rx=\"49\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-415.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__start__</text>\n",
       "</g>\n",
       "<!-- start_conversation -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>start_conversation</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M199.12,-335.94C199.12,-335.94 358.73,-335.94 358.73,-335.94 364.73,-335.94 370.73,-341.94 370.73,-347.94 370.73,-347.94 370.73,-359.94 370.73,-359.94 370.73,-365.94 364.73,-371.94 358.73,-371.94 358.73,-371.94 199.12,-371.94 199.12,-371.94 193.12,-371.94 187.12,-365.94 187.12,-359.94 187.12,-359.94 187.12,-347.94 187.12,-347.94 187.12,-341.94 193.12,-335.94 199.12,-335.94\"/>\n",
       "<text text-anchor=\"start\" x=\"201.53\" y=\"-350.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">start_conversation</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"296.18,-335.94 296.18,-371.94\"/>\n",
       "<text text-anchor=\"start\" x=\"310.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"316.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"319.57\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;start_conversation -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;start_conversation</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-400.94C278.93,-400.94 278.93,-383.91 278.93,-383.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-383.91 278.93,-373.91 275.43,-383.91 282.43,-383.91\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"278.93\" cy=\"-18.14\" rx=\"46.35\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-14.26\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__end__</text>\n",
       "</g>\n",
       "<!-- process_user_message -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>process_user_message</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M333.08,-306.44C333.08,-306.44 224.78,-306.44 224.78,-306.44 218.78,-306.44 212.78,-300.44 212.78,-294.44 212.78,-294.44 212.78,-282.44 212.78,-282.44 212.78,-276.44 218.78,-270.44 224.78,-270.44 224.78,-270.44 333.08,-270.44 333.08,-270.44 339.08,-270.44 345.08,-276.44 345.08,-282.44 345.08,-282.44 345.08,-294.44 345.08,-294.44 345.08,-300.44 339.08,-306.44 333.08,-306.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-284.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">process_user_message</text>\n",
       "</g>\n",
       "<!-- start_conversation&#45;&gt;process_user_message -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>start_conversation&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-335.69C278.93,-335.69 278.93,-318.1 278.93,-318.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-318.1 278.93,-308.1 275.43,-318.1 282.43,-318.1\"/>\n",
       "</g>\n",
       "<!-- response_router -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>response_router</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M270.44,-232.96C270.44,-232.96 232.33,-194.84 232.33,-194.84 228.08,-190.6 228.08,-182.11 232.33,-177.87 232.33,-177.87 270.44,-139.76 270.44,-139.76 274.68,-135.52 283.17,-135.52 287.41,-139.76 287.41,-139.76 325.52,-177.87 325.52,-177.87 329.77,-182.11 329.77,-190.6 325.52,-194.84 325.52,-194.84 287.41,-232.96 287.41,-232.96 283.17,-237.2 274.68,-237.2 270.44,-232.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-188.11\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">response</text>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-176.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">router</text>\n",
       "</g>\n",
       "<!-- process_user_message&#45;&gt;response_router -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>process_user_message&#45;&gt;response_router</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.29,-270.19C297.29,-270.19 297.29,-234.99 297.29,-234.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.79,-234.99 297.29,-224.99 293.79,-234.99 300.79,-234.99\"/>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;process_user_message -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M260.56,-223.5C260.56,-223.5 260.56,-258.56 260.56,-258.56\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"257.06,-258.56 260.56,-268.56 264.06,-258.56 257.06,-258.56\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>make_followup_questions</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M12,-65.77C12,-65.77 203.85,-65.77 203.85,-65.77 209.85,-65.77 215.85,-71.77 215.85,-77.77 215.85,-77.77 215.85,-89.77 215.85,-89.77 215.85,-95.77 209.85,-101.77 203.85,-101.77 203.85,-101.77 12,-101.77 12,-101.77 6,-101.77 0,-95.77 0,-89.77 0,-89.77 0,-77.77 0,-77.77 0,-71.77 6,-65.77 12,-65.77\"/>\n",
       "<text text-anchor=\"start\" x=\"14.4\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">make_followup_questions</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"141.3,-65.77 141.3,-101.77\"/>\n",
       "<text text-anchor=\"start\" x=\"155.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"161.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"164.7\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M228.21,-181.45C228.21,-161.81 228.21,-90 228.21,-90 228.21,-90 227.01,-90 227.01,-90\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"227.75,-86.5 217.75,-90 227.75,-93.5 227.75,-86.5\"/>\n",
       "</g>\n",
       "<!-- summarize_plan -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>summarize_plan</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M354.62,-65.77C354.62,-65.77 505.23,-65.77 505.23,-65.77 511.23,-65.77 517.23,-71.77 517.23,-77.77 517.23,-77.77 517.23,-89.77 517.23,-89.77 517.23,-95.77 511.23,-101.77 505.23,-101.77 505.23,-101.77 354.62,-101.77 354.62,-101.77 348.62,-101.77 342.62,-95.77 342.62,-89.77 342.62,-89.77 342.62,-77.77 342.62,-77.77 342.62,-71.77 348.62,-65.77 354.62,-65.77\"/>\n",
       "<text text-anchor=\"start\" x=\"357.03\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">summarize_plan</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"442.68,-65.77 442.68,-101.77\"/>\n",
       "<text text-anchor=\"start\" x=\"457.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"463.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"466.07\" y=\"-80.9\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. after</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;summarize_plan -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;summarize_plan</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M329.64,-181.42C329.64,-160.22 329.64,-78 329.64,-78 329.64,-78 330.91,-78 330.91,-78\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"330.83,-81.5 340.83,-78 330.83,-74.5 330.83,-81.5\"/>\n",
       "</g>\n",
       "<!-- finalize_plan -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>finalize_plan</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M308.32,-101.77C308.32,-101.77 249.53,-101.77 249.53,-101.77 243.53,-101.77 237.53,-95.77 237.53,-89.77 237.53,-89.77 237.53,-77.77 237.53,-77.77 237.53,-71.77 243.53,-65.77 249.53,-65.77 249.53,-65.77 308.32,-65.77 308.32,-65.77 314.32,-65.77 320.32,-71.77 320.32,-77.77 320.32,-77.77 320.32,-89.77 320.32,-89.77 320.32,-95.77 314.32,-101.77 308.32,-101.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.93\" y=\"-79.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">finalize_plan</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;finalize_plan -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;finalize_plan</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M278.93,-130.86C278.93,-130.86 278.93,-113.63 278.93,-113.63\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"282.43,-113.63 278.93,-103.63 275.43,-113.63 282.43,-113.63\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions&#45;&gt;process_user_message -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>make_followup_questions&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.12,-78C218.51,-78 219.85,-78 219.85,-78 219.85,-78 219.85,-258.62 219.85,-258.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.35,-258.62 219.85,-268.62 223.35,-258.62 216.35,-258.62\"/>\n",
       "</g>\n",
       "<!-- summarize_plan&#45;&gt;process_user_message -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>summarize_plan&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M342.25,-90C339.75,-90 338.32,-90 338.32,-90 338.32,-90 338.32,-258.61 338.32,-258.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"334.82,-258.61 338.32,-268.61 341.82,-258.61 334.82,-258.61\"/>\n",
       "</g>\n",
       "<!-- finalize_plan&#45;&gt;__end__ -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>finalize_plan&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.93,-65.49C278.93,-65.49 278.93,-47.84 278.93,-47.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.43,-47.84 278.93,-37.84 275.43,-47.84 282.43,-47.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x105effd90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_graph_state = PlannerState()\n",
    "\n",
    "graph = planner_graph(plan_graph_state, checkpoint_storage=storage)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run without using checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node '__start__' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'start_conversation' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.start_conversation.<locals>.StartConversationResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10eb33b90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x10e9788c0> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10e940710>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:00:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1450'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999835'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_1831c1787b938929803a7b718d216665'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BPJM8fUTSS0VgGooU8gcN68UQRvX159HsvskQTCto4w-1739160035-1.0.1.1-koUpuxhh.hxak0annykfCTM0IanqoyuphEke7isf2DCi2bygk4BBrDUce3NpmQ6nhjqy3AvN_ecf2kP.DF6roA; path=/; expires=Mon, 10-Feb-25 04:30:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ii44mniukiket75v2Vk3N16WRr3b_QTKG7VQS6lJ9xc-1739160035078-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f931605a21bf03-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 10 Feb 2025 04:00:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'lfm-l6lfkw'), ('openai-processing-ms', '1450'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999835'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_1831c1787b938929803a7b718d216665'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=BPJM8fUTSS0VgGooU8gcN68UQRvX159HsvskQTCto4w-1739160035-1.0.1.1-koUpuxhh.hxak0annykfCTM0IanqoyuphEke7isf2DCi2bygk4BBrDUce3NpmQ6nhjqy3AvN_ecf2kP.DF6roA; path=/; expires=Mon, 10-Feb-25 04:30:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ii44mniukiket75v2Vk3N16WRr3b_QTKG7VQS6lJ9xc-1739160035078-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f931605a21bf03-YYC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_1831c1787b938929803a7b718d216665\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGD7mlRNRipCHcrdlh7r60ewnpu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_atPljKYNWtVfSvTKOfoVD8NN', function=Function(arguments='{\"response\":\"Welcome! I\\'m here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you\\'d like to mention, feel free to do so. Let\\'s get started!\"}', name='StartConversationResponse'), type='function')]))], created=1739160033, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_50cad350e4', usage=CompletionUsage(completion_tokens=62, prompt_tokens=200, total_tokens=262, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_cdba8330-6046-49d2-8186-ff6c9d870da2' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: start_conversation\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'start_conversation'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_4e3fe7aa-c9f8-4947-a88c-eae6adfb4f6b' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: start_conversation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal planning. Could you please share your goal</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements that you'd like to mention, feel free to do so. Let's get started!\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x10e7b5210</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'start_conversation'\u001b[0m, \u001b[32m'__start__'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal planning. Could you please share your goal\u001b[0m\n",
       "\u001b[32min a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or \u001b[0m\n",
       "\u001b[32mrequirements that you'd like to mention, feel free to do so. Let's get started!\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x10e7b5210\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain_id = await graph.execute()\n",
    "# rprint(plan_graph_state)\n",
    "# rprint(graph.chain_status)\n",
    "rprint(graph.execution_engine.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state before resume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal planning. Could you please share your goal</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements that you'd like to mention, feel free to do so. Let's get started!\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x10e7b5210</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'start_conversation'\u001b[0m, \u001b[32m'__start__'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal planning. Could you please share your goal\u001b[0m\n",
       "\u001b[32min a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or \u001b[0m\n",
       "\u001b[32mrequirements that you'd like to mention, feel free to do so. Let's get started!\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x10e7b5210\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_2fb14574-a2c8-4e5e-864f-67f8fb89653c' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after state update\n",
      "DEBUG:primeGraph.graph.engine:Resuming execution on all paused branches...\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'process_user_message' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}] model_message=None user_message='I want to plan a wedding' is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state after resume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">state before processing user message\n",
       "</pre>\n"
      ],
      "text/plain": [
       "state before processing user message\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal planning. Could you please share your goal in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements that you'd like to mention, feel free to do so. Let's get started!\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal planning. Could you please share your goal in \u001b[0m\n",
       "\u001b[32ma clear and concise manner? If you have any relevant context, details, success criteria, constraints, or \u001b[0m\n",
       "\u001b[32mrequirements that you'd like to mention, feel free to do so. Let's get started!\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding'\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.process_user_message.<locals>.ProcessMessageResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:00:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1272'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999338'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'19ms'), (b'x-request-id', b'req_c1fb23a95d679ce06bb3bbfe0354c1b2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f9316bcd05bf03-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 10 Feb 2025 04:00:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '1272', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999338', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '19ms', 'x-request-id': 'req_c1fb23a95d679ce06bb3bbfe0354c1b2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f9316bcd05bf03-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_c1fb23a95d679ce06bb3bbfe0354c1b2\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGF3A3eBywvsM4UCPDdo9mkhBG4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_J0wffYPts7H3vh7ef72ZBEML', function=Function(arguments='{\"plan_goal\":\"Plan a wedding\",\"plan_details\":[],\"is_followup\":true,\"is_summarize\":false,\"is_finalize\":false,\"is_outside_of_the_workflow\":false}', name='ProcessMessageResponse'), type='function')]))], created=1739160035, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=41, prompt_tokens=702, total_tokens=743, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">chat completion\n",
       "</pre>\n"
      ],
      "text/plain": [
       "chat completion\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProcessMessageResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Plan a wedding'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mProcessMessageResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m'Plan a wedding'\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_5eb452f1-bab8-4613-ade7-9d1b0d724a21' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: process_user_message\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'response_router' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='Plan a wedding' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Router node 'response_router' routing to node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'response_router' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'process_user_message' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'make_followup_questions' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}] model_message=None user_message=None is_followup=True is_summarize=False is_finalize=False is_outside_of_the_workflow=False plan_goal='Plan a wedding' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.make_followup_questions.<locals>.FollowupResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you with your goal planning. Could you please share your goal in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or requirements that you'd like to mention, feel free to do so. Let's get started!\"}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': 'I want to plan a wedding'}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:00:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'5887'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999625'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_b1b0070ab73399ae74b1e3fff571f887'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f931752eabbf03-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 10 Feb 2025 04:00:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '5887', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999625', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_b1b0070ab73399ae74b1e3fff571f887', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f931752eabbf03-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_b1b0070ab73399ae74b1e3fff571f887\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGGkbU131gxIoDnfuu4CnsV1fU7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YGYgiMiFHtCEgKom92plSQlk', function=Function(arguments='{\"plan_goal\":\"Plan a wedding\",\"plan_details\":[],\"current_information_assessment\":\"The user wants to plan a wedding, but no additional details or preferences have been provided yet.\",\"follow_up_questions\":[\"What is the proposed date for the wedding?\",\"What is the budget for the wedding?\",\"How many guests are you expecting?\",\"Do you have a preferred location or venue in mind?\",\"What is the overall theme or style of the wedding you envision?\",\"Are there any specific traditions or cultural elements you want to include?\",\"What are your top priorities for this wedding (e.g. venue, food, entertainment)?\",\"Do you require any specific accommodations for guests or family members?\",\"What is your preferred mode of communication throughout the planning process?\"],\"response\":\"To effectively plan your wedding, I need to gather some additional details from you. Could you please share:\\\\n1. The proposed date for the wedding?\\\\n2. Your budget for the wedding?\\\\n3. The expected number of guests?\\\\n4. Your preferred location or venue?\\\\n5. The overall theme or style you envision for the wedding?\\\\n6. Any specific traditions or cultural elements you\\'d like to include?\\\\n7. Your top priorities for the wedding (e.g., venue, food, entertainment)?\\\\n8. Any specific accommodations needed for guests or family members?\\\\n9. Your preferred mode of communication throughout the planning process?\\\\n\\\\nThese details will help in formulating a plan that meets your expectations.\"}', name='FollowupResponse'), type='function')]))], created=1739160036, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_50cad350e4', usage=CompletionUsage(completion_tokens=304, prompt_tokens=476, total_tokens=780, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_88a7ddb7-1137-4b08-b423-a184599d9fda' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'make_followup_questions'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_7a9ee68f-c964-44b1-b5a4-db8df3b366e1' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'make_followup_questions'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'process_user_message'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'response_router'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'make_followup_questions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you with your goal planning. Could you please share your goal</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">requirements that you'd like to mention, feel free to do so. Let's get started!\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"To effectively plan your wedding, I need to gather some additional details from you. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Could you please share:\\n1. The proposed date for the wedding?\\n2. Your budget for the wedding?\\n3. The expected </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of guests?\\n4. Your preferred location or venue?\\n5. The overall theme or style you envision for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">wedding?\\n6. Any specific traditions or cultural elements you'd like to include?\\n7. Your top priorities for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">wedding (e.g., venue, food, entertainment)?\\n8. Any specific accommodations needed for guests or family </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">members?\\n9. Your preferred mode of communication throughout the planning process?\\n\\nThese details will help in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">formulating a plan that meets your expectations.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To effectively plan your wedding, I need to gather some additional details from you. Could </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you please share:\\n1. The proposed date for the wedding?\\n2. Your budget for the wedding?\\n3. The expected number </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of guests?\\n4. Your preferred location or venue?\\n5. The overall theme or style you envision for the wedding?\\n6. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Any specific traditions or cultural elements you'd like to include?\\n7. Your top priorities for the wedding (e.g., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">venue, food, entertainment)?\\n8. Any specific accommodations needed for guests or family members?\\n9. Your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preferred mode of communication throughout the planning process?\\n\\nThese details will help in formulating a plan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that meets your expectations.\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Plan a wedding'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user wants to plan a wedding, but no additional details or preferences </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">have been provided yet.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is the proposed date for the wedding?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is the budget for the wedding?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'How many guests are you expecting?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Do you have a preferred location or venue in mind?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is the overall theme or style of the wedding you envision?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Are there any specific traditions or cultural elements you want to include?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What are your top priorities for this wedding (e.g. venue, food, entertainment)?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Do you require any specific accommodations for guests or family members?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is your preferred mode of communication throughout the planning process?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x10e7b5210</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'make_followup_questions'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m, \u001b[32m'__start__'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'process_user_message'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'response_router'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'make_followup_questions'\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you with your goal planning. Could you please share your goal\u001b[0m\n",
       "\u001b[32min a clear and concise manner? If you have any relevant context, details, success criteria, constraints, or \u001b[0m\n",
       "\u001b[32mrequirements that you'd like to mention, feel free to do so. Let's get started!\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"To effectively plan your wedding, I need to gather some additional details from you. \u001b[0m\n",
       "\u001b[32mCould you please share:\\n1. The proposed date for the wedding?\\n2. Your budget for the wedding?\\n3. The expected \u001b[0m\n",
       "\u001b[32mnumber of guests?\\n4. Your preferred location or venue?\\n5. The overall theme or style you envision for the \u001b[0m\n",
       "\u001b[32mwedding?\\n6. Any specific traditions or cultural elements you'd like to include?\\n7. Your top priorities for the \u001b[0m\n",
       "\u001b[32mwedding \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., venue, food, entertainment\u001b[0m\u001b[32m)\u001b[0m\u001b[32m?\\n8. Any specific accommodations needed for guests or family \u001b[0m\n",
       "\u001b[32mmembers?\\n9. Your preferred mode of communication throughout the planning process?\\n\\nThese details will help in \u001b[0m\n",
       "\u001b[32mformulating a plan that meets your expectations.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m effectively plan your wedding, I need to gather some additional details from you. Could \u001b[0m\n",
       "\u001b[32myou please share:\\n1. The proposed date for the wedding?\\n2. Your budget for the wedding?\\n3. The expected number \u001b[0m\n",
       "\u001b[32mof guests?\\n4. Your preferred location or venue?\\n5. The overall theme or style you envision for the wedding?\\n6. \u001b[0m\n",
       "\u001b[32mAny specific traditions or cultural elements you'd like to include?\\n7. Your top priorities for the wedding \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., \u001b[0m\n",
       "\u001b[32mvenue, food, entertainment\u001b[0m\u001b[32m)\u001b[0m\u001b[32m?\\n8. Any specific accommodations needed for guests or family members?\\n9. Your \u001b[0m\n",
       "\u001b[32mpreferred mode of communication throughout the planning process?\\n\\nThese details will help in formulating a plan \u001b[0m\n",
       "\u001b[32mthat meets your expectations.\"\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m'Plan a wedding'\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m'The user wants to plan a wedding, but no additional details or preferences \u001b[0m\n",
       "\u001b[32mhave been provided yet.'\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[32m'What is the proposed date for the wedding?'\u001b[0m,\n",
       "            \u001b[32m'What is the budget for the wedding?'\u001b[0m,\n",
       "            \u001b[32m'How many guests are you expecting?'\u001b[0m,\n",
       "            \u001b[32m'Do you have a preferred location or venue in mind?'\u001b[0m,\n",
       "            \u001b[32m'What is the overall theme or style of the wedding you envision?'\u001b[0m,\n",
       "            \u001b[32m'Are there any specific traditions or cultural elements you want to include?'\u001b[0m,\n",
       "            \u001b[32m'What are your top priorities for this wedding \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. venue, food, entertainment\u001b[0m\u001b[32m)\u001b[0m\u001b[32m?'\u001b[0m,\n",
       "            \u001b[32m'Do you require any specific accommodations for guests or family members?'\u001b[0m,\n",
       "            \u001b[32m'What is your preferred mode of communication throughout the planning process?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x10e7b5210\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"state before resume\")\n",
    "rprint(graph.execution_engine.get_full_state())\n",
    "\n",
    "message = \"I want to plan a wedding\"\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": message, \n",
    "                                   \"conversation\": {\"role\": \"user\", \"content\": message}})\n",
    "print(\"state after resume\")\n",
    "chain_id = await graph.resume()\n",
    "# rprint(plan_graph_state)\n",
    "# rprint(graph.chain_status)\n",
    "rprint(graph.execution_engine.get_full_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node '__start__' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'start_conversation' with state: version='dd988265246c182af79f41146612fc0b' conversation=[] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.start_conversation.<locals>.StartConversationResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are a helpful assistant that is able to help the user with their goals.\\n\\nYou are part of a workflow for the user to plan for something. This is the first step of the workflow.\\n\\nGive the user a welcome in a brief way and prepare them to start sharing their goal. Things you need to let the user know:\\n\\n- They should share their goal in a clear and concise manner\\n- [OPTIONAL] they should share any relevant context or details about the goal\\n- [OPTIONAL] They should express what success looks like for this goal\\n- [OPTIONAL] They should share any constraints or requirements for the goal\\n'}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'StartConversationResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'StartConversationResponse', 'description': 'Correctly extracted `StartConversationResponse` with all the required parameters with correct types', 'parameters': {'properties': {'response': {'description': 'Your response to the user', 'title': 'Response', 'type': 'string'}}, 'required': ['response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105f006d0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x122378830> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x121a0fc90>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:00:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1623'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999835'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_c793354a8f5942ece4e4c6adecd13376'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qQ7Yb8nS5Z63G9ZVpB2kmJfLyr8FH6eADO3yR5WRB.8-1739160059-1.0.1.1-3nHoeNt475ZeZc6gJB_NNNXf8N4DgZURQIIjpmefN_AdtnlxJBbCswJ4mlQOAXGjmVeICbh.4oqn0pjBGXvk7w; path=/; expires=Mon, 10-Feb-25 04:30:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=RrtTjZGu31V5vu4kvSvtWotxZQhxaToZoFEMIiR.mLk-1739160059945-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f931fbb974befe-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 10 Feb 2025 04:00:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'lfm-l6lfkw'), ('openai-processing-ms', '1623'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999835'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_c793354a8f5942ece4e4c6adecd13376'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=qQ7Yb8nS5Z63G9ZVpB2kmJfLyr8FH6eADO3yR5WRB.8-1739160059-1.0.1.1-3nHoeNt475ZeZc6gJB_NNNXf8N4DgZURQIIjpmefN_AdtnlxJBbCswJ4mlQOAXGjmVeICbh.4oqn0pjBGXvk7w; path=/; expires=Mon, 10-Feb-25 04:30:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=RrtTjZGu31V5vu4kvSvtWotxZQhxaToZoFEMIiR.mLk-1739160059945-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f931fbb974befe-YYC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c793354a8f5942ece4e4c6adecd13376\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGcPzzzPRhOOaWHmgcQ6VeQOwxi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9GY0LZxEdqJWY790wa0N6z2r', function=Function(arguments='{\"response\":\"Welcome! I\\'m here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}', name='StartConversationResponse'), type='function')]))], created=1739160058, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_50cad350e4', usage=CompletionUsage(completion_tokens=60, prompt_tokens=200, total_tokens=260, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_5095cc41-69ac-4041-b1c2-0a53ed03b121' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: start_conversation\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'start_conversation'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_b673031f-c8a1-47fc-ac3d-afb192408985' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: start_conversation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x121e84910</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share\u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x121e84910\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"first execution\")\n",
    "chain_id = await graph.execute()\n",
    "# rprint(plan_graph_state)\n",
    "# rprint(graph.chain_status)\n",
    "rprint(graph.execution_engine.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state before state update\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x121e84910</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share\u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x121e84910\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Patching `client.chat.completions.create` with mode=<Mode.TOOLS: 'tool_call'>\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "DEBUG:primeGraph.graph.executable:Loaded checkpoint checkpoint_b673031f-c8a1-47fc-ac3d-afb192408985 for chain chain_2506c6cc-0a04-43d1-9d00-8b75b63a953a\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_fa705db6-ed50-400d-bb2a-dc53867e1521' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after state update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state after state update\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x12277c3d0</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share\u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding party'\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'0'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x12277c3d0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Patching `client.chat.completions.create` with mode=<Mode.TOOLS: 'tool_call'>\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "DEBUG:primeGraph.graph.executable:Loaded checkpoint checkpoint_fa705db6-ed50-400d-bb2a-dc53867e1521 for chain chain_2506c6cc-0a04-43d1-9d00-8b75b63a953a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state right before resume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share \u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding party'\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1223fc950</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share\u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding party'\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'0'\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x1223fc950\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:primeGraph.graph.engine:Resuming execution on all paused branches...\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.RUNNING\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'process_user_message' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">state before processing user message\n",
       "</pre>\n"
      ],
      "text/plain": [
       "state before processing user message\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share \u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding party'\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.process_user_message.<locals>.ProcessMessageResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow in this is the second (and more important) step.\\n\\nYour goal is to analyze the user's message and route them to the next step in the workflow.\\n\\nYou will be given the user's message and the conversation history. Give more weight to the user's message than the conversation history.\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information about the goal and the conversation history\\n- Assess if the information gathered is enough to create a good plan\\n- Route user to the next step in the workflow\\n- Make sure you capture user's intent and route them to the correct step\\n- Make the user experience seemless and seamless\\n\\n==== WORKFLOW STEPS =====\\n\\nEverything evolve around you capacity to create a good plan in the end. \\nBased on the information gathered, evaluate the following:\\n\\nIF information about the goal, details, or anything that can help you create a good plan is needed:\\n- [Follow up questions]\\n    - Ask follow up questions to gather more information about the goal\\n    - Analyze all the information gathered and judge if addional information is needed\\n    - Be clear and concise with the follow up questions\\n\\nIF all the information is gathered and/or the user is ready to move forward, choose between:\\n- [Summarize and ask permission]: \\n    - Help the user visualize the high level plan\\n    - Share your plan into macro steps with a brief summary of what each step entails\\n    - Check if the user would like to proceed with the next step\\n- [Finalize]: If the summary is approved, or the user is saying that they are ready to move forward, you should proceed to the next step\\n\\nUnrelated:\\n- [Outside of the workflow]: The user is explicitly asking to move out of the plan workflow or explicitly saying that they are done or want to cancel.\\n\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to the user's message\\n- Try to understand the user's intent\\n- Always pick only ONE of the options presented to you on WORKFLOW STEPS\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'ProcessMessageResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'ProcessMessageResponse', 'description': 'Correctly extracted `ProcessMessageResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional relevant details of the plan', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'is_followup': {'title': 'Is Followup', 'type': 'boolean'}, 'is_summarize': {'title': 'Is Summarize', 'type': 'boolean'}, 'is_finalize': {'title': 'Is Finalize', 'type': 'boolean'}, 'is_outside_of_the_workflow': {'title': 'Is Outside Of The Workflow', 'type': 'boolean'}}, 'required': ['is_finalize', 'is_followup', 'is_outside_of_the_workflow', 'is_summarize', 'plan_details', 'plan_goal'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1227d3210>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12237b2f0> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1227d65d0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:01:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'1089'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999336'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'19ms'), (b'x-request-id', b'req_01fd749bcdb4497b70ff76d7bd96a5de'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mlTDrWtVjMxtpmWyqtY52z6PVEin_1.u9gc6TTTyX5M-1739160061-1.0.1.1-zlV0I2SZ.jCp_elRF6d4z1c8OsNDmzeE.8etpdX6JEAyjV625VfPswri24e8LJVtcdwqBpncu.IBpizhnIue5A; path=/; expires=Mon, 10-Feb-25 04:31:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.pGApiYDkG9sdER3KtWpj5.EeFFF6_M.ZnCYSnhuXn8-1739160061500-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f93207bc0dbeea-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 10 Feb 2025 04:01:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'lfm-l6lfkw'), ('openai-processing-ms', '1089'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999336'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '19ms'), ('x-request-id', 'req_01fd749bcdb4497b70ff76d7bd96a5de'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mlTDrWtVjMxtpmWyqtY52z6PVEin_1.u9gc6TTTyX5M-1739160061-1.0.1.1-zlV0I2SZ.jCp_elRF6d4z1c8OsNDmzeE.8etpdX6JEAyjV625VfPswri24e8LJVtcdwqBpncu.IBpizhnIue5A; path=/; expires=Mon, 10-Feb-25 04:31:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.pGApiYDkG9sdER3KtWpj5.EeFFF6_M.ZnCYSnhuXn8-1739160061500-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f93207bc0dbeea-YYC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_01fd749bcdb4497b70ff76d7bd96a5de\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGewwFXnzjWfc402nk9fct3FOUr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_DGDozO5XIpv15y42v1w8lLRP', function=Function(arguments='{\"plan_goal\":\"Plan a wedding party\",\"plan_details\":[],\"is_followup\":true,\"is_summarize\":false,\"is_finalize\":false,\"is_outside_of_the_workflow\":false}', name='ProcessMessageResponse'), type='function')]))], created=1739160060, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_4691090a87', usage=CompletionUsage(completion_tokens=42, prompt_tokens=703, total_tokens=745, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">chat completion\n",
       "</pre>\n"
      ],
      "text/plain": [
       "chat completion\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProcessMessageResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Plan a wedding party'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mProcessMessageResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m'Plan a wedding party'\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_6e5fde8b-e7b8-4c7c-82f1-d2ae6a676389' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: process_user_message\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'response_router' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:primeGraph.graph.engine:Router node 'response_router' routing to node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'process_user_message' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Removing downstream node 'response_router' from visited nodes for re-execution\n",
      "DEBUG:primeGraph.graph.engine:Executing node 'make_followup_questions' with state: version='dd988265246c182af79f41146612fc0b' conversation=[{'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}] model_message=None user_message=None is_followup=None is_summarize=None is_finalize=None is_outside_of_the_workflow=None plan_goal='' plan_summary='' plan_steps=[] plan_details=[] current_information_assessment='' follow_up_questions=[]\n",
      "DEBUG:instructor:Instructor Request: mode.value='tool_call', response_model=<class '__main__.planner_graph.<locals>.make_followup_questions.<locals>.FollowupResponse'>, new_kwargs={'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}}\n",
      "DEBUG:instructor:max_retries: 3\n",
      "DEBUG:instructor:Retrying, attempt: 1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n==== OVERALL GUIDANCE =====\\nYou are in a planning workflow and this is a follow up step.\\n\\nYour goal is to analyze the user's goal, the information gathered and the conversation history.\\nBased on the information gathered, you should ask follow up questions to gather more information about the goal.\\n\\n\\n__ The main goal for this entire planning process: __\\n\\n- Break down the user goal in the planning steps that are:\\n    - Clear\\n    - Concise\\n    - Easy to understand\\n    - Easy to follow\\n\\n__ The main goal with this step is to: __\\n\\n- Analyze current information\\n- Make additional follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n==== GUIDELINES ON HOW TO ACT =====\\n\\n- Pay extreme attention to all the curren information gathered\\n- Identify the gaps into a good planning to achieve the goal and the information needed to fill those gaps\\n- Make follow up questions ONLY IF NEEDED\\n    - The act of gather more information should be to make sure that the planning process has its goals achieved\\n\\n\"}, {'role': 'assistant', 'content': \"Welcome! I'm here to help you plan and achieve your goals. To get started, please share your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks like, and any constraints or requirements you have for this goal.\"}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': 'I want to plan a wedding party'}, {'role': 'user', 'content': []}], 'model': 'gpt-4o', 'tool_choice': {'type': 'function', 'function': {'name': 'FollowupResponse'}}, 'tools': [{'type': 'function', 'function': {'name': 'FollowupResponse', 'description': 'Correctly extracted `FollowupResponse` with all the required parameters with correct types', 'parameters': {'properties': {'plan_goal': {'description': 'The main goal of the plan', 'title': 'Plan Goal', 'type': 'string'}, 'plan_details': {'description': 'Any additional you got from your interactions with the user', 'items': {'type': 'string'}, 'title': 'Plan Details', 'type': 'array'}, 'current_information_assessment': {'description': 'A brief assessment of the current information gathered', 'title': 'Current Information Assessment', 'type': 'string'}, 'follow_up_questions': {'description': 'The follow up questions that you think are needed to gather more information about the goal', 'items': {'type': 'string'}, 'title': 'Follow Up Questions', 'type': 'array'}, 'response': {'description': 'Your response with the follow up questions', 'title': 'Response', 'type': 'string'}}, 'required': ['current_information_assessment', 'follow_up_questions', 'plan_details', 'plan_goal', 'response'], 'type': 'object'}}}]}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 04:01:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'lfm-l6lfkw'), (b'openai-processing-ms', b'4274'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999623'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_1a19575c6c459f1892a4cad312055883'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f93210bd0dbeea-YYC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 10 Feb 2025 04:01:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '4274', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999623', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_1a19575c6c459f1892a4cad312055883', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f93210bd0dbeea-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_1a19575c6c459f1892a4cad312055883\n",
      "DEBUG:instructor:Instructor Raw Response: ChatCompletion(id='chatcmpl-AzFGfoUGyBPOSh0wt1oS8do7ixZeu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ni92pTBkQyZoaCV5on31GUzR', function=Function(arguments='{\"plan_goal\":\"Plan a wedding party\",\"plan_details\":[],\"current_information_assessment\":\"The user wants to plan a wedding party but has not provided specific details about their preferences, budget, guest count, or any particular requirements.\",\"follow_up_questions\":[\"What is the ideal date and time for the wedding party?\",\"How many guests are you planning to invite?\",\"Do you have a specific budget in mind for the wedding party?\",\"What type of venue are you considering?\",\"Are there any particular themes or styles you envision for the wedding?\",\"Would you need any specific services like catering, music, or photography?\",\"Are there any cultural or religious traditions you would like to include?\"],\"response\":\"To help plan your wedding party effectively, I need a bit more information. Could you share details about the ideal date and time, guest count, and budget? Additionally, let me know if you have preferences for the venue, theme, or specific services you need.\"}', name='FollowupResponse'), type='function')]))], created=1739160061, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_50cad350e4', usage=CompletionUsage(completion_tokens=196, prompt_tokens=476, total_tokens=672, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_ae02c7ad-2ab2-4f6f-8390-f4c0c4198312' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n",
      "DEBUG:primeGraph.graph.engine:[Interrupt-after] Executed node 'make_followup_questions'.\n",
      "DEBUG:primeGraph.graph.executable:Chain status updated to: ChainStatus.PAUSE\n",
      "INFO:primeGraph.checkpoint.postgresql:Checkpoint 'checkpoint_c112de38-b4ea-4d02-81d4-fe30094e1c7d' saved to PostgreSQL\n",
      "DEBUG:primeGraph.graph.executable:Checkpoint saved after node: make_followup_questions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state post resume\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'execution_frames'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'visited_nodes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'make_followup_questions'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_execution_count'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'__start__'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_conversation'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'process_user_message'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'response_router'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'make_followup_questions'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'branch_counter'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'active_branches'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'graph_state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dd988265246c182af79f41146612fc0b'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">your goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">like, and any constraints or requirements you have for this goal.\"</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'To help plan your wedding party effectively, I need a bit more information. Could you </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">share details about the ideal date and time, guest count, and budget? Additionally, let me know if you have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preferences for the venue, theme, or specific services you need.'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'To help plan your wedding party effectively, I need a bit more information. Could you share </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details about the ideal date and time, guest count, and budget? Additionally, let me know if you have preferences </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for the venue, theme, or specific services you need.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_summarize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_finalize</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_the_workflow</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Plan a wedding party'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">current_information_assessment</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user wants to plan a wedding party but has not provided specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details about their preferences, budget, guest count, or any particular requirements.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">follow_up_questions</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What is the ideal date and time for the wedding party?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'How many guests are you planning to invite?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Do you have a specific budget in mind for the wedding party?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'What type of venue are you considering?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Are there any particular themes or styles you envision for the wedding?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Would you need any specific services like catering, music, or photography?'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Are there any cultural or religious traditions you would like to include?'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chain_status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PAUSE'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'interrupted_frames'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">primeGraph.graph.engine.ExecutionFrame</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1223fc950</span><span style=\"font-weight: bold\">&gt;}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'execution_frames'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'visited_nodes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'make_followup_questions'\u001b[0m, \u001b[32m'__start__'\u001b[0m, \u001b[32m'start_conversation'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'node_execution_count'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'__start__'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'start_conversation'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'process_user_message'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'response_router'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "        \u001b[32m'make_followup_questions'\u001b[0m: \u001b[1;36m1\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'branch_counter'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'active_branches'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'graph_state'\u001b[0m: \u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'dd988265246c182af79f41146612fc0b'\u001b[0m,\n",
       "        \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m\"Welcome! I'm here to help you plan and achieve your goals. To get started, please share\u001b[0m\n",
       "\u001b[32myour goal in a clear and concise manner. If it helps, include any relevant context or details, what success looks \u001b[0m\n",
       "\u001b[32mlike, and any constraints or requirements you have for this goal.\"\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[32m'content'\u001b[0m: \u001b[32m'To help plan your wedding party effectively, I need a bit more information. Could you \u001b[0m\n",
       "\u001b[32mshare details about the ideal date and time, guest count, and budget? Additionally, let me know if you have \u001b[0m\n",
       "\u001b[32mpreferences for the venue, theme, or specific services you need.'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33mmodel_message\u001b[0m=\u001b[32m'To help plan your wedding party effectively, I need a bit more information. Could you share \u001b[0m\n",
       "\u001b[32mdetails about the ideal date and time, guest count, and budget? Additionally, let me know if you have preferences \u001b[0m\n",
       "\u001b[32mfor the venue, theme, or specific services you need.'\u001b[0m,\n",
       "        \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[33mis_summarize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mis_finalize\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mis_outside_of_the_workflow\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mplan_goal\u001b[0m=\u001b[32m'Plan a wedding party'\u001b[0m,\n",
       "        \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "        \u001b[33mplan_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcurrent_information_assessment\u001b[0m=\u001b[32m'The user wants to plan a wedding party but has not provided specific \u001b[0m\n",
       "\u001b[32mdetails about their preferences, budget, guest count, or any particular requirements.'\u001b[0m,\n",
       "        \u001b[33mfollow_up_questions\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[32m'What is the ideal date and time for the wedding party?'\u001b[0m,\n",
       "            \u001b[32m'How many guests are you planning to invite?'\u001b[0m,\n",
       "            \u001b[32m'Do you have a specific budget in mind for the wedding party?'\u001b[0m,\n",
       "            \u001b[32m'What type of venue are you considering?'\u001b[0m,\n",
       "            \u001b[32m'Are there any particular themes or styles you envision for the wedding?'\u001b[0m,\n",
       "            \u001b[32m'Would you need any specific services like catering, music, or photography?'\u001b[0m,\n",
       "            \u001b[32m'Are there any cultural or religious traditions you would like to include?'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'chain_status'\u001b[0m: \u001b[32m'PAUSE'\u001b[0m,\n",
       "    \u001b[32m'interrupted_frames'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1m<\u001b[0m\u001b[1;95mprimeGraph.graph.engine.ExecutionFrame\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x1223fc950\u001b[0m\u001b[1m>\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"state before state update\")\n",
    "rprint(graph.execution_engine.get_full_state())\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I want to plan a wedding party\", \n",
    "                                   \"conversation\": {\"role\": \"user\", \"content\": \"I want to plan a wedding party\"}})\n",
    "print(\"state after state update\")\n",
    "# rprint(graph.state)\n",
    "rprint(graph.execution_engine.get_full_state())\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "print(\"state right before resume\")\n",
    "rprint(graph.state)\n",
    "rprint(graph.execution_engine.get_full_state())\n",
    "\n",
    "await graph.resume()\n",
    "print(\"state post resume\") \n",
    "# rprint(graph.state)\n",
    "# rprint(graph.chain_status)\n",
    "rprint(graph.execution_engine.get_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_engine.get_full_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I don't have any of these details\"})\n",
    "print(\"state_pre_checkpoint\")\n",
    "rprint(graph.state)\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "await graph.resume_async()\n",
    "print(\"state_post_checkpoint\") \n",
    "rprint(graph.state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
